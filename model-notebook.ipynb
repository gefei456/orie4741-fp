{
 "cells": [
  {
   "cell_type": "code",
   "id": "6e504281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:51.706780Z",
     "start_time": "2025-01-14T01:09:51.701495Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a341b52b",
   "metadata": {},
   "source": [
    "## 0. DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9469f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:51.823435Z",
     "start_time": "2025-01-14T01:09:51.707784Z"
    }
   },
   "source": [
    "football_df = pd.read_csv('data/all_data_with_elo.csv', low_memory = False)\n",
    "football_df"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fcbbc3ce",
   "metadata": {},
   "source": [
    "## 1. Descriptive Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b828a5",
   "metadata": {},
   "source": [
    "**1.1 DataFrame Shape**"
   ]
  },
  {
   "cell_type": "code",
   "id": "15427373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:51.829954Z",
     "start_time": "2025-01-14T01:09:51.824443Z"
    }
   },
   "source": [
    "# no. rows and no. cols\n",
    "football_df.shape"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7b649b14",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:51.840478Z",
     "start_time": "2025-01-14T01:09:51.829954Z"
    }
   },
   "source": [
    "# feature names\n",
    "print(football_df.columns.tolist())"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb560ee",
   "metadata": {},
   "source": [
    "**1.2 NaN Values**"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3377302",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:53.799974Z",
     "start_time": "2025-01-14T01:09:53.790989Z"
    }
   },
   "source": [
    "football_df.isnull().sum()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7eae5438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:55.636221Z",
     "start_time": "2025-01-14T01:09:55.631751Z"
    }
   },
   "source": [
    "# total elements in \n",
    "football_df.size"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2afbc469",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:56.868432Z",
     "start_time": "2025-01-14T01:09:56.858770Z"
    }
   },
   "source": [
    "# total number of NaN\n",
    "football_df.size - football_df.count().sum()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a9b3446d",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:57.871948Z",
     "start_time": "2025-01-14T01:09:57.863187Z"
    }
   },
   "source": [
    "# total number of NaN rows\n",
    "football_df.isnull().any(axis = 1).sum()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "12fcf2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:09:59.098644Z",
     "start_time": "2025-01-14T01:09:59.089277Z"
    }
   },
   "source": [
    "# total number of NaN columns\n",
    "football_df.isnull().any(axis = 0).sum()"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "da2853e2",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling and Feature Transformation/Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde42d8",
   "metadata": {},
   "source": [
    "### 2.1 NaN Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34fc35",
   "metadata": {},
   "source": [
    "`TODO`: drop NaN values along columns: {Date, Home Team, Away Team, FTR} <br>\n",
    "`TODO`: identify betting odds w/ most available data"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f75f7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:01.471218Z",
     "start_time": "2025-01-14T01:10:01.466872Z"
    }
   },
   "source": [
    "# 当前方法仅提取这几个字段 分区 日期 主队 客队 full-time-result 三家机构的胜平负 主队ELO评分 客队ELO评分\n",
    "nan_mask = ['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTR', 'B365H', 'B365D', 'B365A', \n",
    "            'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA', 'HomeTeamELO', 'AwayTeamELO']"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1e6545f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:02.539543Z",
     "start_time": "2025-01-14T01:10:02.509999Z"
    }
   },
   "source": [
    "# 删除指定列中含有缺失值的行\n",
    "#football_df.FTR.replace('nan', np.nan, inplace=True)\n",
    "nan_football_df = football_df.dropna(subset = nan_mask)\n",
    "nan_football_df"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ad42e459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:04.714251Z",
     "start_time": "2025-01-14T01:10:04.708239Z"
    }
   },
   "source": [
    "# resize shape\n",
    "football_df.shape[0] - nan_football_df.shape[0]"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "42864535",
   "metadata": {},
   "source": [
    "### 2.2 Feature Encoding <br>\n",
    "* $\\phi(Date)$ $\\Rightarrow$ one column for *year*, second column for *month*, third column for *day of year*\n",
    "* One hot encode Division, Home and Away Teams\n",
    "* Label encode Full Time Result (Win/Draw/Loss)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b5bb61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:07.202780Z",
     "start_time": "2025-01-14T01:10:07.198623Z"
    }
   },
   "source": [
    "feats = nan_mask"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:08.284337Z",
     "start_time": "2025-01-14T01:10:08.279321Z"
    }
   },
   "cell_type": "code",
   "source": "nan_mask",
   "id": "2d27ae22b3d65d5a",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:10.194744Z",
     "start_time": "2025-01-14T01:10:10.172100Z"
    }
   },
   "cell_type": "code",
   "source": "nan_football_df",
   "id": "9919d74193a28304",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:12.372251Z",
     "start_time": "2025-01-14T01:10:12.354303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_df = nan_football_df.copy()[feats]\n",
    "learning_df"
   ],
   "id": "5213f7b7293d7cc0",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fe16f1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:14.309507Z",
     "start_time": "2025-01-14T01:10:14.294865Z"
    }
   },
   "source": [
    "learning_df.reset_index(inplace=True, drop=True)\n",
    "learning_df"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "15884417",
   "metadata": {},
   "source": [
    "**2.2.1 Division and Home/Away Team Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "id": "913c0088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:16.484152Z",
     "start_time": "2025-01-14T01:10:16.291787Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "div_encoder = OneHotEncoder()\n",
    "home_encoder = OneHotEncoder()\n",
    "away_encoder = OneHotEncoder()"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bc739d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:18.411806Z",
     "start_time": "2025-01-14T01:10:18.361980Z"
    }
   },
   "source": [
    "onehot_div = div_encoder.fit_transform(learning_df.Div.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_div_df = pd.DataFrame(onehot_div, columns = [\"Div \"+str(int(i)) for i in range(onehot_div.shape[1])])\n",
    "\n",
    "onehot_home = home_encoder.fit_transform(learning_df.HomeTeam.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_home_df = pd.DataFrame(onehot_home, columns = ['HomeTeam ' + str(int(i)) for i in np.arange(onehot_home.shape[1])])\n",
    "\n",
    "onehot_away = away_encoder.fit_transform(learning_df.AwayTeam.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_away_df = pd.DataFrame(onehot_away, columns = ['AwayTeam ' + str(int(i)) for i in np.arange(onehot_away.shape[1])])"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f8444147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:19.643056Z",
     "start_time": "2025-01-14T01:10:19.575294Z"
    }
   },
   "source": [
    "learning_df = pd.concat([learning_df, onehot_div_df, onehot_home_df, onehot_away_df], axis = 1)\n",
    "learning_df.drop(columns = ['Div'], inplace = True)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "321f2f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:20.827680Z",
     "start_time": "2025-01-14T01:10:20.809365Z"
    }
   },
   "source": [
    "learning_df"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0fefa3",
   "metadata": {},
   "source": [
    "**2.2.2 Full Time Result Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "id": "f9442a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:23.840269Z",
     "start_time": "2025-01-14T01:10:23.833111Z"
    }
   },
   "source": [
    "target_encoder = LabelEncoder()\n",
    "learning_df['Result'] = target_encoder.fit_transform(learning_df.FTR) "
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "18c1cb41",
   "metadata": {},
   "source": [
    "**2.2.3 Date Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5dfc529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:25.641938Z",
     "start_time": "2025-01-14T01:10:25.583369Z"
    }
   },
   "source": [
    "learning_df['Year'] = pd.DatetimeIndex(learning_df.Date).year\n",
    "\n",
    "learning_df['Month'] = pd.DatetimeIndex(learning_df.Date).month\n",
    "learning_df['Sin_Month'] = np.sin(2*np.pi*learning_df.Month/12)\n",
    "learning_df['Cos_Month'] = np.cos(2*np.pi*learning_df.Month/12)\n",
    "\n",
    "learning_df['DayofYear'] = pd.DatetimeIndex(learning_df.Date).dayofyear\n",
    "learning_df['Sin_Day'] = np.sin(2*np.pi*learning_df.DayofYear/365)\n",
    "learning_df['Cos_Day'] = np.cos(2*np.pi*learning_df.DayofYear/365)\n",
    "\n",
    "learning_df.drop(columns = ['Date','Month'], inplace = True)\n",
    "# learning_df.drop(columns = ['Date'], inplace = True)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7e7bc241",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:27.424946Z",
     "start_time": "2025-01-14T01:10:27.401705Z"
    }
   },
   "source": [
    "learning_df"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b14da74e",
   "metadata": {},
   "source": [
    "### 2.3 Feature Engineering <br>\n",
    "* $\\phi(x)$ feature transformation $\\Rightarrow$ last match result, win/loss streak to date, wins to season date\n",
    "* $\\phi(x)$ feature engineering $\\Rightarrow$ average the home, away, and draw odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843342cb",
   "metadata": {},
   "source": [
    "**2.3.1 Last Match Result** <br>\n",
    "Indicate the result from the last match played between both teams"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9871315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:31.007055Z",
     "start_time": "2025-01-14T01:10:31.001668Z"
    }
   },
   "source": [
    "# 定义一个函数来计算两队之间上一场比赛的结果\n",
    "def compute_lastmatchres(df):\n",
    "    \n",
    "    unique_matchups = list(set((list(zip(df.HomeTeam, df.AwayTeam)))))\n",
    "    df['Last Match Result'] = np.nan\n",
    "    for home, away in unique_matchups:\n",
    "        matchup_df = df[(df.HomeTeam == home) & (df.AwayTeam == away)]\n",
    "        # 使用 shift(1) 方法将 FTR（全场比赛结果）列中的数据向下移动一行，这样每行的 last_match_result 将对应于这两队之前的一场比赛的结果。fill_value='Na' 确保了数据移动后空出的位置填充为 'Na'。\n",
    "        last_match_result = matchup_df.FTR.shift(1, fill_value='Na')\n",
    "        df.loc[matchup_df.index, 'Last Match Result'] = last_match_result\n",
    "        \n",
    "    lmr_encoder = LabelEncoder()\n",
    "    df['Last Match Result'] = lmr_encoder.fit_transform(df['Last Match Result'])\n",
    "    df.drop(columns = ['FTR'], inplace = True)\n",
    "    return df"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "751bdc97",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T01:10:51.963312Z",
     "start_time": "2025-01-14T01:10:32.617172Z"
    }
   },
   "source": [
    "learning_df = compute_lastmatchres(learning_df)\n",
    "# learning_df.drop(columns = ['FTR'], inplace = True)"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8ff554cf",
   "metadata": {},
   "source": [
    "**2.3.2 Home and Away Win/Loss Streak** <br>\n",
    "Important note about this feature: the win/loss streak is the teams *home* and *away* win streak, *not* its ***consecutive*** win/loss streak."
   ]
  },
  {
   "cell_type": "code",
   "id": "41f1fcc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:24:42.527902Z",
     "start_time": "2024-06-11T23:24:42.524899Z"
    }
   },
   "source": [
    "# https://stackoverflow.com/questions/52976336/compute-winning-streak-with-pandas\n",
    "# https://joshdevlin.com/blog/calculate-streaks-in-pandas/"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4658caa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:24:42.544536Z",
     "start_time": "2024-06-11T23:24:42.528414Z"
    }
   },
   "source": [
    "def compute_winstreak(df):\n",
    "    \n",
    "    years = df.Year.unique()\n",
    "    df_lst = []    \n",
    "    for year in years:\n",
    "        \n",
    "        year_df = df[df.Year == year]\n",
    "        year_df['HomeWin'] = year_df.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "        year_df['AwayWin'] = year_df.Result.replace([0, 1, 2], [1, 0, 0])\n",
    "        year_df['HomeWinStreak'] = None\n",
    "        year_df['AwayWinStreak'] = None\n",
    "        \n",
    "        hometeams = year_df.HomeTeam.unique()\n",
    "        awayteams = year_df.AwayTeam.unique()\n",
    "        \n",
    "        for team in hometeams:\n",
    "            team_df = year_df[(year_df.HomeTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_grouper = (team_df.HomeWin != team_df.HomeWin.shift()).cumsum()\n",
    "            team_df['HomeWinStreak'] = team_df[['HomeWin']].groupby(team_grouper).cumsum()\n",
    "            team_df.loc[team_df.HomeWinStreak >0, 'HomeWinStreak'] -= 1\n",
    "            year_df.loc[team_df.index, 'HomeWinStreak'] = team_df.HomeWinStreak\n",
    "            \n",
    "        for team in awayteams:\n",
    "            team_df = year_df[(year_df.AwayTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_grouper = (team_df.AwayWin != team_df.AwayWin.shift()).cumsum()\n",
    "            team_df['AwayWinStreak'] = team_df[['AwayWin']].groupby(team_grouper).cumsum()\n",
    "            team_df.loc[team_df.AwayWinStreak >0, 'AwayWinStreak'] -= 1\n",
    "            year_df.loc[team_df.index, 'AwayWinStreak'] = team_df.AwayWinStreak\n",
    "            \n",
    "        df_lst.append(year_df)\n",
    "        \n",
    "    return pd.concat(df_lst, axis = 0).drop(columns = ['HomeWin', 'AwayWin'])#,'DayofYear'])"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "aca53647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:24:55.403835Z",
     "start_time": "2024-06-11T23:24:42.544536Z"
    }
   },
   "source": [
    "learning_df = compute_winstreak(learning_df)"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "94e1c235",
   "metadata": {},
   "source": [
    "**2.3.4 Season Home/Away Wins to Date** <br>\n",
    "Indicate the number of wins for a team as home and away to date within current season"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb9c5f13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:24:55.414726Z",
     "start_time": "2024-06-11T23:24:55.404848Z"
    }
   },
   "source": [
    "toy = learning_df[(learning_df.Year == 2010) & (learning_df.HomeTeam == 'Barcelona')][['HomeTeam', 'AwayTeam', 'Result']]\n",
    "toy['HomeWin'] = toy.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "toy['HomeWinsToDate'] = toy.HomeWin.cumsum()"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "885dc94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:24:55.421177Z",
     "start_time": "2024-06-11T23:24:55.415738Z"
    }
   },
   "source": [
    "def compute_winstodate(df):\n",
    "    \n",
    "    years = df.Year.unique()\n",
    "    df_lst = []    \n",
    "    for year in years:\n",
    "        \n",
    "        year_df = df[df.Year == year]\n",
    "        year_df['HomeWin'] = year_df.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "        year_df['AwayWin'] = year_df.Result.replace([0, 1, 2], [1, 0, 0])\n",
    "        year_df['HomeWinsToDate'] = None\n",
    "        year_df['AwayWinsToDate'] = None\n",
    "        \n",
    "        hometeams = year_df.HomeTeam.unique()\n",
    "        awayteams = year_df.AwayTeam.unique()\n",
    "        \n",
    "        for team in hometeams:\n",
    "            team_df = year_df[(year_df.HomeTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_df['HomeWinsToDate'] = team_df.HomeWin.cumsum()\n",
    "            year_df.loc[team_df.index, 'HomeWinsToDate'] = team_df.HomeWinsToDate\n",
    "            \n",
    "        for team in awayteams:\n",
    "            team_df = year_df[(year_df.AwayTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "            \n",
    "            team_df['AwayWinsToDate'] = team_df.AwayWin.cumsum()\n",
    "            year_df.loc[team_df.index, 'AwayWinsToDate'] = team_df.AwayWinsToDate\n",
    "            \n",
    "        df_lst.append(year_df)\n",
    "        \n",
    "    return pd.concat(df_lst, axis = 0).drop(columns = ['HomeWin', 'AwayWin','DayofYear'])"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b60fbbf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.151502Z",
     "start_time": "2024-06-11T23:24:55.422185Z"
    }
   },
   "source": [
    "learning_df = compute_winstodate(learning_df)\n",
    "learning_df.drop(columns = ['HomeTeam', 'AwayTeam'], inplace = True)"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "36c2496f",
   "metadata": {},
   "source": [
    "**2.3.5 Website Odds** <br>\n",
    "The `betting odds` recorded by various betting websites offer insight into sentiment surrounding the outcome of a particular game. "
   ]
  },
  {
   "cell_type": "code",
   "id": "1efc8290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.160452Z",
     "start_time": "2024-06-11T23:25:02.153515Z"
    }
   },
   "source": [
    "betting_feats = ['B365H', 'B365D', 'B365A', 'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA']\n",
    "betting_feats"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "031548ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.173396Z",
     "start_time": "2024-06-11T23:25:02.160972Z"
    }
   },
   "source": [
    "def compute_meanodds(df, betting_feats):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    home_odds = []\n",
    "    away_odds = []\n",
    "    draw_odds = []\n",
    "    for odd in betting_feats:\n",
    "        odd_type = odd[-1]\n",
    "        if odd_type == 'H':\n",
    "            home_odds.append(odd)\n",
    "        elif odd_type == 'A':\n",
    "            away_odds.append(odd)\n",
    "        else:\n",
    "            draw_odds.append(odd)\n",
    "    avg_home_odds = df[home_odds].mean(axis=1)\n",
    "    avg_away_odds = df[away_odds].mean(axis=1)\n",
    "    avg_draw_odds = df[draw_odds].mean(axis=1)\n",
    "    \n",
    "    ordered_cols = ['HomeOdds', 'AwayOdds', 'DrawOdds'] + df.columns.tolist()\n",
    "    \n",
    "    df['HomeOdds'] = avg_home_odds\n",
    "    df['AwayOdds'] = avg_away_odds\n",
    "    df['DrawOdds'] = avg_draw_odds\n",
    "    \n",
    "    return df[ordered_cols]"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "08e0a28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.211160Z",
     "start_time": "2024-06-11T23:25:02.174402Z"
    }
   },
   "source": [
    "learning_df = compute_meanodds(learning_df, betting_feats)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0e4768c8",
   "metadata": {},
   "source": [
    "### 2.4 Peek @ Learning DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "b54348f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.243379Z",
     "start_time": "2024-06-11T23:25:02.212186Z"
    }
   },
   "source": [
    "learning_df"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7b46d936",
   "metadata": {},
   "source": [
    "# 3. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e10788",
   "metadata": {},
   "source": [
    "* Establish a baseline Logistic Regression model fit over the entire learning dataframe without special regard to *division* and *team*. \n",
    "* Train model over 16 seasons, and predict for the remaining 3 seasons (approximate 80-20 split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ddd44e",
   "metadata": {},
   "source": [
    "### 3.1 Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "id": "a82f4a6b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.247051Z",
     "start_time": "2024-06-11T23:25:02.244398Z"
    }
   },
   "source": [
    "split = 0.80\n",
    "no_seasons = 20\n",
    "\n",
    "print('No. seasons to train over: ' + str(round(split*no_seasons)))"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f22ecde1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.271666Z",
     "start_time": "2024-06-11T23:25:02.248068Z"
    }
   },
   "source": [
    "X, y = learning_df.loc[:, learning_df.columns != 'Result'], learning_df[['Result']]"
   ],
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "60373664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.274894Z",
     "start_time": "2024-06-11T23:25:02.271666Z"
    }
   },
   "source": [
    "# full_feat = ['HomeWinStreak','AwayWinStreak','HomeWinsToDate', 'AwayWinsToDate', 'Last Match Result',\n",
    "#              'HomeTeamELO', 'AwayTeamELO', 'HomeOdds', 'AwayOdds', 'DrawOdds'] + betting_feats\n",
    "\n",
    "# exclude_feats = ['HomeWinsToDate', 'AwayWinsToDate', 'Last Match Result'] "
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1db1f4fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.280853Z",
     "start_time": "2024-06-11T23:25:02.275914Z"
    }
   },
   "source": [
    "# X = X[X.columns[~X.columns.isin(exclude_feats)]]\n",
    "# X"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4c621fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.317564Z",
     "start_time": "2024-06-11T23:25:02.281870Z"
    }
   },
   "source": [
    "X"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.323827Z",
     "start_time": "2024-06-11T23:25:02.318582Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "232473f400896cfa",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.329049Z",
     "start_time": "2024-06-11T23:25:02.324832Z"
    }
   },
   "cell_type": "code",
   "source": "split_year = 2020",
   "id": "44dc55d09c257a7d",
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0e361977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.378870Z",
     "start_time": "2024-06-11T23:25:02.330060Z"
    }
   },
   "source": [
    "# 切分训练集和测试集\n",
    "xTr, xTe = X[X.Year <= split_year], X[X.Year > split_year]\n",
    "yTr, yTe = y.loc[xTr.index, :], y.loc[xTe.index, :]"
   ],
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Normalization <br>\n",
    "Following our various feature transformations and development, we arrived to a sparse dataframe with the exception of a few features(*Year, DayofYear*). It will be important to *normalize* these features as they are in gross magnitudes compared to the remaining features. During model training, having dominating features (in scale relative to others) can be dangerous as the weight updates may mistakengly favor these larger-scale features because it will have the largest influence on the target output. "
   ],
   "id": "50636cdc8bb898d6"
  },
  {
   "cell_type": "code",
   "id": "a72d269a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.388677Z",
     "start_time": "2024-06-11T23:25:02.379875Z"
    }
   },
   "source": [
    "# minmax_scaler.fit_transform()：这个方法首先拟合数据，即计算数据的最小值和最大值，这些值用于后续的缩放。然后，它将这些参数用于转换数据，将原始数据缩放到0和1之间。\n",
    "# minmax_scaler.transform()：这个方法使用在训练数据上计算得到的最小值和最大值来转换测试数据。这确保了训练数据和测试数据使用相同的缩放标准。\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "xTr.loc[:, ['Year']] = minmax_scaler.fit_transform(xTr.loc[:, ['Year']])\n",
    "xTe.loc[:, ['Year']] = minmax_scaler.transform(xTe.loc[:, ['Year']])"
   ],
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "11ee9c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.467576Z",
     "start_time": "2024-06-11T23:25:02.389683Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "to_scale = ['HomeWinStreak','AwayWinStreak','HomeWinsToDate', 'AwayWinsToDate', 'HomeTeamELO', 'AwayTeamELO', 'HomeOdds', 'AwayOdds', 'DrawOdds'] + betting_feats\n",
    "\n",
    "xTr.loc[:, to_scale] = std_scaler.fit_transform(xTr.loc[:, to_scale])\n",
    "xTe.loc[:, to_scale] = std_scaler.transform(xTe.loc[:, to_scale])"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "76792bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.497629Z",
     "start_time": "2024-06-11T23:25:02.468596Z"
    }
   },
   "source": [
    "xTr"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4696b592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.511819Z",
     "start_time": "2024-06-11T23:25:02.498640Z"
    }
   },
   "source": [
    "xTe"
   ],
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8b0abe45",
   "metadata": {},
   "source": [
    "### 3.3 HomeWins Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8002824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.564829Z",
     "start_time": "2024-06-11T23:25:02.512827Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.568956Z",
     "start_time": "2024-06-11T23:25:02.565848Z"
    }
   },
   "cell_type": "code",
   "source": "xTr.shape",
   "id": "bdd8d4925bb687b9",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.575429Z",
     "start_time": "2024-06-11T23:25:02.569966Z"
    }
   },
   "cell_type": "code",
   "source": "xTe.shape",
   "id": "53f767c6fd6ea837",
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f13115e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.582357Z",
     "start_time": "2024-06-11T23:25:02.576447Z"
    }
   },
   "source": [
    "# training score\n",
    "baseline_Tr = np.full((xTr.shape[0], 1), 2) \n",
    "accuracy_score(yTr.Result.values, baseline_Tr.ravel())"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "16d2cf5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:02.587682Z",
     "start_time": "2024-06-11T23:25:02.583376Z"
    }
   },
   "source": [
    "# testing score\n",
    "baseline_preds_Te = np.full((xTe.shape[0]  , 1), 2) #predicts home wins all the time\n",
    "accuracy_score(yTe.Result.values, baseline_preds_Te.ravel())"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dff87ca8",
   "metadata": {},
   "source": [
    "### 3.4 Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03fdd6",
   "metadata": {},
   "source": [
    "**3.4.1** $l2$ Regularized"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c5f52f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:13.746986Z",
     "start_time": "2024-06-11T23:25:02.588698Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l2_lr = LogisticRegression(max_iter = 10000, n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "54140ce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:14.186511Z",
     "start_time": "2024-06-11T23:25:13.747995Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l2_lr.predict(xTr))"
   ],
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8c59602e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:14.275937Z",
     "start_time": "2024-06-11T23:25:14.187021Z"
    }
   },
   "source": [
    "# testing score\n",
    "lr_preds = l2_lr.predict(xTe)\n",
    "accuracy_score(yTe.Result.values, lr_preds)"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8adcb166",
   "metadata": {},
   "source": [
    "**3.4.1** $l2$ Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "3009cb8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:26.634989Z",
     "start_time": "2024-06-11T23:25:14.276947Z"
    }
   },
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "logistic_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "# logistic_randsearch = RandomizedSearchCV(estimator=LogisticRegression(max_iter=10000),\n",
    "#                                          param_distributions=logistic_params,\n",
    "logistic_randsearch = GridSearchCV(estimator=LogisticRegression(max_iter=10000),\n",
    "                                         param_grid=logistic_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=1,\n",
    "                                         cv=5,\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "logistic_rand_results = logistic_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (logistic_rand_results.best_score_, logistic_rand_results.best_params_))"
   ],
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a9231529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:26.639804Z",
     "start_time": "2024-06-11T23:25:26.636001Z"
    }
   },
   "source": [
    "l2_rs = logistic_rand_results.best_estimator_"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9197a0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:27.075185Z",
     "start_time": "2024-06-11T23:25:26.640809Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l2_rs.predict(xTr))"
   ],
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5c45f431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:25:27.169940Z",
     "start_time": "2024-06-11T23:25:27.076195Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, l2_rs.predict(xTe))"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "febcc06f",
   "metadata": {},
   "source": [
    "**3.4.4** $l1$ Regularized"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9502351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:29:55.078763Z",
     "start_time": "2024-06-11T23:25:27.170967Z"
    }
   },
   "source": [
    "l1_lr = LogisticRegression(penalty='l1', solver='saga', max_iter = 10000, n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "82d75648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:29:55.540169Z",
     "start_time": "2024-06-11T23:29:55.079277Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l1_lr.predict(xTr))"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4faea9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:29:55.628548Z",
     "start_time": "2024-06-11T23:29:55.541177Z"
    }
   },
   "source": [
    "# testing score\n",
    "l1_preds = l1_lr.predict(xTe)\n",
    "accuracy_score(yTe.Result.values, l1_preds)"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "445dcdb4",
   "metadata": {},
   "source": [
    "**3.4.5** Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "3314235e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:34:52.661143Z",
     "start_time": "2024-06-11T23:29:55.629552Z"
    }
   },
   "source": [
    "l1_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "# l1_randsearch = RandomizedSearchCV(estimator=LogisticRegression(penalty='l1',solver='saga', max_iter=10000),\n",
    "#                                          param_distributions=l1_params,\n",
    "l1_randsearch = GridSearchCV(estimator=LogisticRegression(penalty='l1',solver='saga', max_iter=10000),\n",
    "                                         param_grid=l1_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=1,\n",
    "                                         n_jobs=-1,\n",
    "                                         cv=5)\n",
    "\n",
    "l1_rand_results = l1_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (l1_rand_results.best_score_, l1_rand_results.best_params_))"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f4607e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:34:52.665347Z",
     "start_time": "2024-06-11T23:34:52.662158Z"
    }
   },
   "source": [
    "l1_rs = l1_randsearch.best_estimator_ #LogisticRegression(C=0.10, solver='saga', max_iter=10000).fit(xTr, yTr.values.ravel())#"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4895d05a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:34:53.121934Z",
     "start_time": "2024-06-11T23:34:52.665520Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l1_rs.predict(xTr))"
   ],
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7016a84c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:34:53.224284Z",
     "start_time": "2024-06-11T23:34:53.122943Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, l1_rs.predict(xTe))"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8b988c26",
   "metadata": {},
   "source": [
    "### 3.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "id": "0f4908d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:38:20.446870Z",
     "start_time": "2024-06-11T23:34:53.225300Z"
    }
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(max_iter=100000).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1a18a45a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:41:32.740189Z",
     "start_time": "2024-06-11T23:38:20.447885Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, svm.predict(xTr))"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7311630d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T23:42:08.321245Z",
     "start_time": "2024-06-11T23:41:32.741198Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, svm.predict(xTe))"
   ],
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f00bed",
   "metadata": {},
   "source": [
    "**3.5.2** Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b998f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:02:05.180489Z",
     "start_time": "2024-06-11T23:42:08.322260Z"
    }
   },
   "source": [
    "svm_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "# svm_randsearch = RandomizedSearchCV(estimator=SVC(max_iter=100000),\n",
    "#                                          param_distributions=svm_params,\n",
    "svm_randsearch = GridSearchCV(estimator=SVC(max_iter=100000),\n",
    "                                         param_grid=svm_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=2,\n",
    "                                         cv=5,\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "svm_rand_results = svm_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (svm_rand_results.best_score_, svm_rand_results.best_params_))"
   ],
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7f9627ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:02:05.185874Z",
     "start_time": "2024-06-12T00:02:05.181493Z"
    }
   },
   "source": [
    "svm_rs = svm_rand_results.best_estimator_"
   ],
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e32e6caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:05:23.468121Z",
     "start_time": "2024-06-12T00:02:05.186386Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, svm_rs.predict(xTr))"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e88837b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:05:59.552523Z",
     "start_time": "2024-06-12T00:05:23.469165Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, svm_rs.predict(xTe))"
   ],
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "edee8858",
   "metadata": {},
   "source": [
    "### 3.6 Simple Neural Network ####"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0505f91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:18:26.843178Z",
     "start_time": "2024-06-12T00:05:59.553532Z"
    }
   },
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512,128,32),\n",
    "                    activation='relu',\n",
    "                    batch_size=64,\n",
    "                    max_iter=200,\n",
    "                    learning_rate_init=1e-4,\n",
    "                    early_stopping=False,\n",
    "                    alpha=1e-3,\n",
    "                   ).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5ca78c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:18:27.507666Z",
     "start_time": "2024-06-12T00:18:26.844233Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, mlp.predict(xTr))"
   ],
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "aa884592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:18:27.707809Z",
     "start_time": "2024-06-12T00:18:27.508671Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, mlp.predict(xTe))"
   ],
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4656a5",
   "metadata": {},
   "source": [
    "### 3.7 Stacked Classifier ###"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a2f0890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:18:27.711159Z",
     "start_time": "2024-06-12T00:18:27.708824Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ],
   "execution_count": 78,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "94e15eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:26:52.086594Z",
     "start_time": "2024-06-12T00:18:27.712166Z"
    }
   },
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "stacked_clf = StackingClassifier(estimators=[('svm', SVC(max_iter=100000)), ('logistic', LogisticRegression(C=0.01, max_iter=10000))],\n",
    "                                final_estimator=LogisticRegression(max_iter=10000),\n",
    "                                n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 79,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b22e6db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:29:55.640337Z",
     "start_time": "2024-06-12T00:26:52.091774Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, stacked_clf.predict(xTr))"
   ],
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7a57d164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.109204Z",
     "start_time": "2024-06-12T00:29:55.641348Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, stacked_clf.predict(xTe))"
   ],
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e90e8cae",
   "metadata": {},
   "source": [
    "## 4. Result Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "id": "0d4a4507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.113395Z",
     "start_time": "2024-06-12T00:30:29.110219Z"
    }
   },
   "source": [
    "## TODO: breakdown results across divisions and/or teams; i.e., see how model performs individually at subgroups"
   ],
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a10a069c",
   "metadata": {},
   "source": [
    "## 5. Scrap Code ##"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d631c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.148064Z",
     "start_time": "2024-06-12T00:30:29.114410Z"
    }
   },
   "source": [
    "barcelona_df = learning_df[(learning_df['HomeTeam 17'] == 1) | (learning_df['AwayTeam 17'] == 1)]\n",
    "barcelona_df"
   ],
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "38bb2e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.156500Z",
     "start_time": "2024-06-12T00:30:29.149069Z"
    }
   },
   "source": [
    "bxTr = xTr[(xTr['HomeTeam 17'] == 1) | (xTr['AwayTeam 17'] == 1)]\n",
    "bxTe = xTe[(xTe['HomeTeam 17'] == 1) | (xTe['AwayTeam 17'] == 1)]"
   ],
   "execution_count": 84,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "154fa92b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.160959Z",
     "start_time": "2024-06-12T00:30:29.157509Z"
    }
   },
   "source": [
    "byTr, byTe = yTr.loc[bxTr.index,:], yTe.loc[bxTe.index,:]"
   ],
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a0cdf35f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.179490Z",
     "start_time": "2024-06-12T00:30:29.161971Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(byTr, l1_lr.predict(bxTr))"
   ],
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b3c76c88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.189915Z",
     "start_time": "2024-06-12T00:30:29.180494Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(byTe, l1_lr.predict(bxTe))"
   ],
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6c7dad65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.208332Z",
     "start_time": "2024-06-12T00:30:29.190920Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(byTr, l2_lr.predict(bxTr))"
   ],
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e393c3c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.221132Z",
     "start_time": "2024-06-12T00:30:29.209337Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(byTe, l2_lr.predict(bxTe))"
   ],
   "execution_count": 89,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Pytorch MLP ##",
   "id": "1a9d44ed88b506d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.225007Z",
     "start_time": "2024-06-12T00:30:29.222137Z"
    }
   },
   "cell_type": "code",
   "source": "type(xTr)",
   "id": "46c50f7a30542964",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:29.230744Z",
     "start_time": "2024-06-12T00:30:29.225007Z"
    }
   },
   "cell_type": "code",
   "source": "xTr.shape",
   "id": "3d5d6acf5e103ccf",
   "execution_count": 91,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:30:31.848057Z",
     "start_time": "2024-06-12T00:30:29.231749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ],
   "id": "8974fd74dc8ccc05",
   "execution_count": 92,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:32:44.874725Z",
     "start_time": "2024-06-12T00:30:31.849073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.randn(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 应用注意力权重\n",
    "        weights = F.softmax(self.attention_weights, dim=0)\n",
    "        # 加权求和\n",
    "        x = x * weights\n",
    "        return x\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=xTr.shape[1], out_features=512)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=512)\n",
    "        self.attention = Attention(512)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=128)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=128)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=32)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=32)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features=32, out_features=3)  # 输出层改为3，对应三个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(torch.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.attention(x)\n",
    "        x = self.dropout2(torch.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout3(torch.relu(self.bn3(self.fc3(x))))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "xTr_scaled = scaler.fit_transform(xTr)\n",
    "xTr_tensor = torch.tensor(xTr_scaled, dtype=torch.float32).to(device)\n",
    "yTr_tensor = torch.tensor(yTr.values.ravel(), dtype=torch.long).to(device)\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset = TensorDataset(xTr_tensor, yTr_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# 创建模型实例\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "train_start = time.time()\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(500):  # 假设训练200个epoch\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # 清除之前的梯度\n",
    "\n",
    "        outputs = model(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)  # 累计损失\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 获取预测结果\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100  # 计算准确率\n",
    "\n",
    "    # 每个epoch结束后输出\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "print(f'训练时长： {time.time() - train_start}s')"
   ],
   "id": "b2df02ede7062703",
   "execution_count": 93,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:32:45.169598Z",
     "start_time": "2024-06-12T00:32:44.875741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设 xTe 和 yTe 是 pandas DataFrame 或 Series\n",
    "# 数据预处理\n",
    "xTe_scaled = scaler.fit_transform(xTe)  # 使用与训练数据相同的标准化参数\n",
    "xTe_tensor = torch.tensor(xTe_scaled, dtype=torch.float32).to(device)\n",
    "yTe_tensor = torch.tensor(yTe.values.ravel(), dtype=torch.long).to(device)\n",
    "\n",
    "# 创建数据加载器\n",
    "test_dataset = TensorDataset(xTe_tensor, yTe_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于计算准确率的变量\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 不计算梯度，因为在评估模式下不需要进行反向传播\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on test set: {accuracy * 100:.2f}%')"
   ],
   "id": "eaf39c6569e4f89d",
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Pytorch Transformer ##",
   "id": "cf72af33f38ca812"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:38:29.685867Z",
     "start_time": "2024-06-12T00:32:45.170608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, num_layers, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.model_dim = input_dim  # 通常情况下，模型维度与输入维度相同\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.model_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=512,  # 前馈网络的维度\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Transformer Encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(self.model_dim, self.num_classes)\n",
    "\n",
    "        # Batch Normalization\n",
    "        self.bn = nn.BatchNorm1d(self.model_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 增加一个假的序列维度\n",
    "        x = x.unsqueeze(1)\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Batch Normalization\n",
    "        x = self.bn(x[:, 0, :])  # 取序列的第一个元素进行批量归一化\n",
    "\n",
    "        # 输出层\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# 补充维度\n",
    "n_samples_xTr = xTr.shape[0]\n",
    "n_samples_xTe = xTe.shape[0]\n",
    "for i in range(1, 4):  # 从 1 到 3，因为需要添加三列\n",
    "    xTr[f'pad{i}'] = 0  # 添加填充列，初始化为 0\n",
    "    xTe[f'pad{i}'] = 0  # 添加填充列，初始化为 0\n",
    "\n",
    "# 参数设置\n",
    "input_dim = xTr.shape[1]  # 输入特征的维度\n",
    "num_classes = 3  # 类别数\n",
    "num_heads = 10  # 注意力头的数量\n",
    "num_layers = 3  # Transformer层的数量\n",
    "dropout = 0.8  # Dropout比率\n",
    "\n",
    "# 创建模型\n",
    "model = TransformerModel(input_dim, num_classes, num_heads, num_layers, dropout).to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 数据加载\n",
    "# 假设 xTr 和 xTe 已经是适当的 torch.Tensor 对象\n",
    "xTr_values = xTr.values.astype(float)\n",
    "xTe_values = xTe.values.astype(float)\n",
    "\n",
    "xTr_tensor = torch.tensor(xTr_values, dtype=torch.float32).to(device)\n",
    "xTe_tensor = torch.tensor(xTe_values, dtype=torch.float32).to(device)\n",
    "yTr_tensor = torch.tensor(yTr.values, dtype=torch.long).to(device).squeeze(1)\n",
    "yTe_tensor = torch.tensor(yTe.values, dtype=torch.long).to(device).squeeze(1)\n",
    "# 转换为 one-hot 编码\n",
    "yTr_tensor = F.one_hot(yTr_tensor, num_classes=num_classes).float()\n",
    "yTe_tensor = F.one_hot(yTe_tensor, num_classes=num_classes).float()\n",
    "\n",
    "# 数据加载器\n",
    "train_dataset = TensorDataset(xTr_tensor, yTr_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(xTe_tensor, yTe_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "train_start = time.time()\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(500):  # 运行更多的 epoch 以获得更好的结果\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)  # 累计损失\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 获取预测结果\n",
    "        _, truth = torch.max(labels.data, 1)\n",
    "        total += truth.size(0)\n",
    "        correct += (predicted == truth).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100  # 计算准确率\n",
    "\n",
    "    # 每个epoch结束后输出\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "print(f'训练时长： {time.time() - train_start}s')\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于计算准确率的变量\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 不计算梯度，因为在评估模式下不需要进行反向传播\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, truth = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == truth).sum().item()\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on test set: {accuracy * 100:.2f}%')"
   ],
   "id": "b49f583ba5a1498",
   "execution_count": 95,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
