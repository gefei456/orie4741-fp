{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e504281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341b52b",
   "metadata": {},
   "source": [
    "## 0. DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9469f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "football_df = pd.read_csv('all_data_with_elo.csv', low_memory = False)\n",
    "football_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbc3ce",
   "metadata": {},
   "source": [
    "## 1. Descriptive Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b828a5",
   "metadata": {},
   "source": [
    "**1.1 DataFrame Shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15427373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. rows and no. cols\n",
    "football_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b649b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature names\n",
    "print(football_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb560ee",
   "metadata": {},
   "source": [
    "**1.2 NaN Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3377302",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "football_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total elements in \n",
    "football_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbc469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total number of NaN\n",
    "football_df.size - football_df.count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3446d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total number of NaN rows\n",
    "football_df.isnull().any(axis = 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of NaN columns\n",
    "football_df.isnull().any(axis = 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2853e2",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling and Feature Transformation/Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde42d8",
   "metadata": {},
   "source": [
    "### 2.1 NaN Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34fc35",
   "metadata": {},
   "source": [
    "`TODO`: drop NaN values along columns: {Date, Home Team, Away Team, FTR} <br>\n",
    "`TODO`: identify betting odds w/ most available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = ['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTR', 'B365H', 'B365D', 'B365A', \n",
    "            'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA', 'HomeTeamELO', 'AwayTeamELO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6545f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#football_df.FTR.replace('nan', np.nan, inplace=True)\n",
    "nan_football_df = football_df.dropna(subset = nan_mask)\n",
    "nan_football_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize shape\n",
    "football_df.shape[0] - nan_football_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42864535",
   "metadata": {},
   "source": [
    "### 2.2 Feature Encoding <br>\n",
    "* $\\phi(Date)$ $\\Rightarrow$ one column for *year*, second column for *month*, third column for *day of year*\n",
    "* One hot encode Division, Home and Away Teams\n",
    "* Label encode Full Time Result (Win/Draw/Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5bb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = nan_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df = nan_football_df.copy()[feats]\n",
    "learning_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15884417",
   "metadata": {},
   "source": [
    "**2.2.1 Division and Home/Away Team Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "div_encoder = OneHotEncoder()\n",
    "home_encoder = OneHotEncoder()\n",
    "away_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc739d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_div = div_encoder.fit_transform(learning_df.Div.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_div_df = pd.DataFrame(onehot_div, columns = [\"Div \"+str(int(i)) for i in range(onehot_div.shape[1])])\n",
    "\n",
    "onehot_home = home_encoder.fit_transform(learning_df.HomeTeam.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_home_df = pd.DataFrame(onehot_home, columns = ['HomeTeam ' + str(int(i)) for i in np.arange(onehot_home.shape[1])])\n",
    "\n",
    "onehot_away = away_encoder.fit_transform(learning_df.AwayTeam.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_away_df = pd.DataFrame(onehot_away, columns = ['AwayTeam ' + str(int(i)) for i in np.arange(onehot_away.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8444147",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df = pd.concat([learning_df, onehot_div_df, onehot_home_df, onehot_away_df], axis = 1)\n",
    "learning_df.drop(columns = ['Div'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fefa3",
   "metadata": {},
   "source": [
    "**2.2.2 Full Time Result Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9442a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = LabelEncoder()\n",
    "learning_df['Result'] = target_encoder.fit_transform(learning_df.FTR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1cb41",
   "metadata": {},
   "source": [
    "**2.2.3 Date Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dfc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df['Year'] = pd.DatetimeIndex(learning_df.Date).year\n",
    "\n",
    "learning_df['Month'] = pd.DatetimeIndex(learning_df.Date).month\n",
    "learning_df['Sin_Month'] = np.sin(2*np.pi*learning_df.Month/12)\n",
    "learning_df['Cos_Month'] = np.cos(2*np.pi*learning_df.Month/12)\n",
    "\n",
    "learning_df['DayofYear'] = pd.DatetimeIndex(learning_df.Date).dayofyear\n",
    "learning_df['Sin_Day'] = np.sin(2*np.pi*learning_df.DayofYear/365)\n",
    "learning_df['Cos_Day'] = np.cos(2*np.pi*learning_df.DayofYear/365)\n",
    "\n",
    "learning_df.drop(columns = ['Date','Month'], inplace = True)\n",
    "# learning_df.drop(columns = ['Date'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7bc241",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14da74e",
   "metadata": {},
   "source": [
    "### 2.3 Feature Engineering <br>\n",
    "* $\\phi(x)$ feature transformation $\\Rightarrow$ last match result, win/loss streak to date, wins to season date\n",
    "* $\\phi(x)$ feature engineering $\\Rightarrow$ average the home, away, and draw odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843342cb",
   "metadata": {},
   "source": [
    "**2.3.1 Last Match Result** <br>\n",
    "Indicate the result from the last match played between both teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9871315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lastmatchres(df):\n",
    "    \n",
    "    unique_matchups = list(set((list(zip(df.HomeTeam, df.AwayTeam)))))\n",
    "    df['Last Match Result'] = np.nan\n",
    "    for home, away in unique_matchups:\n",
    "        matchup_df = df[(df.HomeTeam == home) & (df.AwayTeam == away)]\n",
    "        last_match_result = matchup_df.FTR.shift(1, fill_value='Na')\n",
    "        df.loc[matchup_df.index, 'Last Match Result'] = last_match_result\n",
    "        \n",
    "    lmr_encoder = LabelEncoder()\n",
    "    df['Last Match Result'] = lmr_encoder.fit_transform(df['Last Match Result'])\n",
    "    df.drop(columns = ['FTR'], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bdc97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_df = compute_lastmatchres(learning_df)\n",
    "# learning_df.drop(columns = ['FTR'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff554cf",
   "metadata": {},
   "source": [
    "**2.3.2 Home and Away Win/Loss Streak** <br>\n",
    "Important note about this feature: the win/loss streak is the teams *home* and *away* win streak, *not* its ***consecutive*** win/loss streak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52976336/compute-winning-streak-with-pandas\n",
    "# https://joshdevlin.com/blog/calculate-streaks-in-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_winstreak(df):\n",
    "    \n",
    "    years = df.Year.unique()\n",
    "    df_lst = []    \n",
    "    for year in years:\n",
    "        \n",
    "        year_df = df[df.Year == year]\n",
    "        year_df['HomeWin'] = year_df.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "        year_df['AwayWin'] = year_df.Result.replace([0, 1, 2], [1, 0, 0])\n",
    "        year_df['HomeWinStreak'] = None\n",
    "        year_df['AwayWinStreak'] = None\n",
    "        \n",
    "        hometeams = year_df.HomeTeam.unique()\n",
    "        awayteams = year_df.AwayTeam.unique()\n",
    "        \n",
    "        for team in hometeams:\n",
    "            team_df = year_df[(year_df.HomeTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_grouper = (team_df.HomeWin != team_df.HomeWin.shift()).cumsum()\n",
    "            team_df['HomeWinStreak'] = team_df[['HomeWin']].groupby(team_grouper).cumsum()\n",
    "            team_df.loc[team_df.HomeWinStreak >0, 'HomeWinStreak'] -= 1\n",
    "            year_df.loc[team_df.index, 'HomeWinStreak'] = team_df.HomeWinStreak\n",
    "            \n",
    "        for team in awayteams:\n",
    "            team_df = year_df[(year_df.AwayTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_grouper = (team_df.AwayWin != team_df.AwayWin.shift()).cumsum()\n",
    "            team_df['AwayWinStreak'] = team_df[['AwayWin']].groupby(team_grouper).cumsum()\n",
    "            team_df.loc[team_df.AwayWinStreak >0, 'AwayWinStreak'] -= 1\n",
    "            year_df.loc[team_df.index, 'AwayWinStreak'] = team_df.AwayWinStreak\n",
    "            \n",
    "        df_lst.append(year_df)\n",
    "        \n",
    "    return pd.concat(df_lst, axis = 0).drop(columns = ['HomeWin', 'AwayWin'])#,'DayofYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca53647",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df = compute_winstreak(learning_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1c235",
   "metadata": {},
   "source": [
    "**2.3.4 Season Home/Away Wins to Date** <br>\n",
    "Indicate the number of wins for a team as home and away to date within current season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = learning_df[(learning_df.Year == 2010) & (learning_df.HomeTeam == 'Barcelona')][['HomeTeam', 'AwayTeam', 'Result']]\n",
    "toy['HomeWin'] = toy.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "toy['HomeWinsToDate'] = toy.HomeWin.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885dc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_winstodate(df):\n",
    "    \n",
    "    years = df.Year.unique()\n",
    "    df_lst = []    \n",
    "    for year in years:\n",
    "        \n",
    "        year_df = df[df.Year == year]\n",
    "        year_df['HomeWin'] = year_df.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "        year_df['AwayWin'] = year_df.Result.replace([0, 1, 2], [1, 0, 0])\n",
    "        year_df['HomeWinsToDate'] = None\n",
    "        year_df['AwayWinsToDate'] = None\n",
    "        \n",
    "        hometeams = year_df.HomeTeam.unique()\n",
    "        awayteams = year_df.AwayTeam.unique()\n",
    "        \n",
    "        for team in hometeams:\n",
    "            team_df = year_df[(year_df.HomeTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_df['HomeWinsToDate'] = team_df.HomeWin.cumsum()\n",
    "            year_df.loc[team_df.index, 'HomeWinsToDate'] = team_df.HomeWinsToDate\n",
    "            \n",
    "        for team in awayteams:\n",
    "            team_df = year_df[(year_df.AwayTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "            \n",
    "            team_df['AwayWinsToDate'] = team_df.AwayWin.cumsum()\n",
    "            year_df.loc[team_df.index, 'AwayWinsToDate'] = team_df.AwayWinsToDate\n",
    "            \n",
    "        df_lst.append(year_df)\n",
    "        \n",
    "    return pd.concat(df_lst, axis = 0).drop(columns = ['HomeWin', 'AwayWin','DayofYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df = compute_winstodate(learning_df)\n",
    "learning_df.drop(columns = ['HomeTeam', 'AwayTeam'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2496f",
   "metadata": {},
   "source": [
    "**2.3.5 Website Odds** <br>\n",
    "The `betting odds` recorded by various betting websites offer insight into sentiment surrounding the outcome of a particular game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_feats = ['B365H', 'B365D', 'B365A', 'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA']\n",
    "betting_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031548ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meanodds(df, betting_feats):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    home_odds = []\n",
    "    away_odds = []\n",
    "    draw_odds = []\n",
    "    for odd in betting_feats:\n",
    "        odd_type = odd[-1]\n",
    "        if odd_type == 'H':\n",
    "            home_odds.append(odd)\n",
    "        elif odd_type == 'A':\n",
    "            away_odds.append(odd)\n",
    "        else:\n",
    "            draw_odds.append(odd)\n",
    "    avg_home_odds = df[home_odds].mean(axis=1)\n",
    "    avg_away_odds = df[away_odds].mean(axis=1)\n",
    "    avg_draw_odds = df[draw_odds].mean(axis=1)\n",
    "    \n",
    "    ordered_cols = ['HomeOdds', 'AwayOdds', 'DrawOdds'] + df.columns.tolist()\n",
    "    \n",
    "    df['HomeOdds'] = avg_home_odds\n",
    "    df['AwayOdds'] = avg_away_odds\n",
    "    df['DrawOdds'] = avg_draw_odds\n",
    "    \n",
    "    return df[ordered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df = compute_meanodds(learning_df, betting_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4768c8",
   "metadata": {},
   "source": [
    "### 2.4 Peek @ Learning DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54348f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46d936",
   "metadata": {},
   "source": [
    "# 3. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e10788",
   "metadata": {},
   "source": [
    "* Establish a baseline Logistic Regression model fit over the entire learning dataframe without special regard to *division* and *team*. \n",
    "* Train model over 16 seasons, and predict for the remaining 3 seasons (approximate 80-20 split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ddd44e",
   "metadata": {},
   "source": [
    "### 3.1 Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f4a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = 0.80\n",
    "no_seasons = 20\n",
    "\n",
    "print('No. seasons to train over: ' + str(round(split*no_seasons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ecde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = learning_df.loc[:, learning_df.columns != 'Result'], learning_df[['Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60373664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_feat = ['HomeWinStreak','AwayWinStreak','HomeWinsToDate', 'AwayWinsToDate', 'Last Match Result',\n",
    "#              'HomeTeamELO', 'AwayTeamELO', 'HomeOdds', 'AwayOdds', 'DrawOdds'] + betting_feats\n",
    "\n",
    "# exclude_feats = ['HomeWinsToDate', 'AwayWinsToDate', 'Last Match Result'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[X.columns[~X.columns.isin(exclude_feats)]]\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c621fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e361977",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr, xTe = X[X.Year <= 2016], X[X.Year > 2016]\n",
    "yTr, yTe = y.loc[xTr.index, :], y.loc[xTe.index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c0b77",
   "metadata": {},
   "source": [
    "### 3.2 Normalization <br>\n",
    "Following our various feature transformations and development, we arrived to a sparse dataframe with the exception of a few features(*Year, DayofYear*). It will be important to *normalize* these features as they are in gross magnitudes compared to the remaining features. During model training, having dominating features (in scale relative to others) can be dangerous as the weight updates may mistakengly favor these larger-scale features because it will have the largest influence on the target output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "xTr.loc[:, ['Year']] = minmax_scaler.fit_transform(xTr.loc[:, ['Year']])\n",
    "xTe.loc[:, ['Year']] = minmax_scaler.transform(xTe.loc[:, ['Year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "to_scale = ['HomeWinStreak','AwayWinStreak','HomeWinsToDate', 'AwayWinsToDate', 'HomeTeamELO', 'AwayTeamELO', 'HomeOdds', 'AwayOdds', 'DrawOdds'] + betting_feats\n",
    "\n",
    "xTr.loc[:, to_scale] = std_scaler.fit_transform(xTr.loc[:, to_scale])\n",
    "xTe.loc[:, to_scale] = std_scaler.transform(xTe.loc[:, to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76792bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0abe45",
   "metadata": {},
   "source": [
    "### 3.3 HomeWins Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8002824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13115e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "baseline_Tr = np.full((24233, 1), 2) \n",
    "accuracy_score(yTr.Result.values, baseline_Tr.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "baseline_preds_Te = np.full((8628  , 1), 2) #predicts home wins all the time\n",
    "accuracy_score(yTe.Result.values, baseline_preds_Te.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff87ca8",
   "metadata": {},
   "source": [
    "### 3.4 Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03fdd6",
   "metadata": {},
   "source": [
    "**3.4.1** $l2$ Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l2_lr = LogisticRegression(max_iter = 10000, n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54140ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l2_lr.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "lr_preds = l2_lr.predict(xTe)\n",
    "accuracy_score(yTe.Result.values, lr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adcb166",
   "metadata": {},
   "source": [
    "**3.4.1** $l2$ Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logistic_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "logistic_randsearch = RandomizedSearchCV(estimator=LogisticRegression(max_iter=10000),\n",
    "                                         param_distributions=logistic_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=1,\n",
    "                                         cv=5,\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "logistic_rand_results = logistic_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (logistic_rand_results.best_score_, logistic_rand_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9231529",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_rs = logistic_rand_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l2_rs.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, l2_rs.predict(xTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcc06f",
   "metadata": {},
   "source": [
    "**3.4.4** $l1$ Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9502351",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_lr = LogisticRegression(penalty='l1', solver='saga', max_iter = 10000, n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d75648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l1_lr.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faea9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "l1_preds = l1_lr.predict(xTe)\n",
    "accuracy_score(yTe.Result.values, l1_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445dcdb4",
   "metadata": {},
   "source": [
    "**3.4.5** Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "l1_randsearch = RandomizedSearchCV(estimator=LogisticRegression(penalty='l1',solver='saga', max_iter=10000),\n",
    "                                         param_distributions=l1_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=1,\n",
    "                                         n_jobs=-1,\n",
    "                                         cv=5)\n",
    "\n",
    "l1_rand_results = l1_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (l1_rand_results.best_score_, l1_rand_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4607e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_rs = l1_randsearch.best_estimator_ #LogisticRegression(C=0.10, solver='saga', max_iter=10000).fit(xTr, yTr.values.ravel())#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l1_rs.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, l1_rs.predict(xTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b988c26",
   "metadata": {},
   "source": [
    "### 3.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4908d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(max_iter=100000).fit(xTr, yTr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, svm.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, svm.predict(xTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f00bed",
   "metadata": {},
   "source": [
    "**3.5.2** Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b998f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "svm_randsearch = RandomizedSearchCV(estimator=SVC(max_iter=100000),\n",
    "                                         param_distributions=svm_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=2,\n",
    "                                         cv=5,\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "svm_rand_results = svm_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (svm_rand_results.best_score_, svm_rand_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9627ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rs = svm_rand_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, svm_rs.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88837b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, svm_rs.predict(xTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee8858",
   "metadata": {},
   "source": [
    "### 3.6 Simple Neural Network ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0505f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512,),\n",
    "                    activation='relu',\n",
    "                    batch_size=64,\n",
    "                    max_iter=1000,\n",
    "                   ).fit(xTr, yTr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca78c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, mlp.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa884592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, mlp.predict(xTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4656a5",
   "metadata": {},
   "source": [
    "### 3.7 Stacked Classifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e15eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "stacked_clf = StackingClassifier(estimators=[('svm', SVC(max_iter=100000)), ('logistic', LogisticRegression(C=0.01, max_iter=10000))],\n",
    "                                final_estimator=LogisticRegression(max_iter=10000),\n",
    "                                n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, stacked_clf.predict(xTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, stacked_clf.predict(xTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e8cae",
   "metadata": {},
   "source": [
    "## 4. Result Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: breakdown results across divisions and/or teams; i.e., see how model performs individually at subgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a069c",
   "metadata": {},
   "source": [
    "## 5. Scrap Code ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d631c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcelona_df = learning_df[(learning_df['HomeTeam 17'] == 1) | (learning_df['AwayTeam 17'] == 1)]\n",
    "barcelona_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bxTr = xTr[(xTr['HomeTeam 17'] == 1) | (xTr['AwayTeam 17'] == 1)]\n",
    "bxTe = xTe[(xTe['HomeTeam 17'] == 1) | (xTe['AwayTeam 17'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154fa92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "byTr, byTe = yTr.loc[bxTr.index,:], yTe.loc[bxTe.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cdf35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(byTr, l1_lr.predict(bxTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c76c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(byTe, l1_lr.predict(bxTe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7dad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score\n",
    "accuracy_score(byTr, l2_lr.predict(bxTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score\n",
    "accuracy_score(byTe, l2_lr.predict(bxTe))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
