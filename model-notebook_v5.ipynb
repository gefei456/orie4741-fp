{
 "cells": [
  {
   "cell_type": "code",
   "id": "6e504281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.024632Z",
     "start_time": "2025-02-04T10:45:26.803167Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "import joblib"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a341b52b",
   "metadata": {},
   "source": [
    "## 0. DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9469f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.186838Z",
     "start_time": "2025-02-04T10:45:28.024632Z"
    }
   },
   "source": [
    "football_df = pd.read_csv('data/all_data_with_elo.csv', low_memory = False)\n",
    "football_df"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fcbbc3ce",
   "metadata": {},
   "source": [
    "## 1. Descriptive Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b828a5",
   "metadata": {},
   "source": [
    "**1.1 DataFrame Shape**"
   ]
  },
  {
   "cell_type": "code",
   "id": "15427373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.202796Z",
     "start_time": "2025-02-04T10:45:28.187864Z"
    }
   },
   "source": [
    "# no. rows and no. cols\n",
    "football_df.shape"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7b649b14",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.235003Z",
     "start_time": "2025-02-04T10:45:28.203802Z"
    }
   },
   "source": [
    "# feature names\n",
    "print(football_df.columns.tolist())"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb560ee",
   "metadata": {},
   "source": [
    "**1.2 NaN Values**"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3377302",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.256138Z",
     "start_time": "2025-02-04T10:45:28.236009Z"
    }
   },
   "source": [
    "football_df.isnull().sum()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7eae5438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.270525Z",
     "start_time": "2025-02-04T10:45:28.257141Z"
    }
   },
   "source": [
    "# total elements in \n",
    "football_df.size"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2afbc469",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.292362Z",
     "start_time": "2025-02-04T10:45:28.270525Z"
    }
   },
   "source": [
    "# total number of NaN\n",
    "football_df.size - football_df.count().sum()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a9b3446d",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.321299Z",
     "start_time": "2025-02-04T10:45:28.293366Z"
    }
   },
   "source": [
    "# total number of NaN rows\n",
    "football_df.isnull().any(axis = 1).sum()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "12fcf2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.340608Z",
     "start_time": "2025-02-04T10:45:28.322304Z"
    }
   },
   "source": [
    "# total number of NaN columns\n",
    "football_df.isnull().any(axis = 0).sum()"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "da2853e2",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling and Feature Transformation/Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde42d8",
   "metadata": {},
   "source": [
    "### 2.1 NaN Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34fc35",
   "metadata": {},
   "source": [
    "`TODO`: drop NaN values along columns: {Date, Home Team, Away Team, FTR} <br>\n",
    "`TODO`: identify betting odds w/ most available data"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f75f7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.373829Z",
     "start_time": "2025-02-04T10:45:28.340608Z"
    }
   },
   "source": [
    "# 当前方法仅提取这几个字段 分区 日期 主队 客队 full-time-result 三家机构的胜平负 主队ELO评分 客队ELO评分\n",
    "# nan_mask = ['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTR', 'B365H', 'B365D', 'B365A', \n",
    "#             'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA', 'AHh', 'B365AHH', 'B365AHA', 'HomeTeamELO', 'AwayTeamELO']\n",
    "nan_mask = ['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'B365H', 'B365D', 'B365A', 'WHH', 'WHD', 'WHA', 'AHh', 'B365AHH', 'B365AHA', 'HomeTeamELO', 'AwayTeamELO']"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.422765Z",
     "start_time": "2025-02-04T10:45:28.374828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nan_football_df = football_df.dropna(subset = nan_mask)\n",
    "nan_football_df"
   ],
   "id": "23e46d7ed335b538",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.464163Z",
     "start_time": "2025-02-04T10:45:28.422765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nan_football_df['asia_final_result'] = nan_football_df['FTHG'] - nan_football_df['FTAG'] + nan_football_df['AHh']\n",
    "nan_football_df"
   ],
   "id": "11c29f5924e5d7a1",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.513037Z",
     "start_time": "2025-02-04T10:45:28.466580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nan_football_df_noNone = nan_football_df.dropna(subset = nan_mask)\n",
    "nan_football_df_noNone"
   ],
   "id": "d1bdaa50359f4dd6",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.547800Z",
     "start_time": "2025-02-04T10:45:28.514040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nan_football_df_noNone.reset_index(inplace=True, drop=True)\n",
    "nan_football_df_noNone"
   ],
   "id": "fd25a49ce3655cb6",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.616027Z",
     "start_time": "2025-02-04T10:45:28.547800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conditions = [\n",
    "    nan_football_df_noNone['asia_final_result'] < -0.25,\n",
    "    nan_football_df_noNone['asia_final_result'] == -0.25,\n",
    "    nan_football_df_noNone['asia_final_result'] == 0,\n",
    "    nan_football_df_noNone['asia_final_result'] == 0.25,\n",
    "    nan_football_df_noNone['asia_final_result'] > 0.25,\n",
    "]\n",
    "easy_conditions = [\n",
    "    nan_football_df_noNone['asia_final_result'] <= -0.25,\n",
    "    nan_football_df_noNone['asia_final_result'] == 0,\n",
    "    nan_football_df_noNone['asia_final_result'] >= 0.25,\n",
    "]\n",
    "labels = [-2, -1, 0, 1, 2]\n",
    "easy_labels = [-1, 0, 1]\n",
    "\n",
    "nan_football_df_noNone['label'] = np.select(conditions, labels)\n",
    "nan_football_df_noNone['easy_label'] = np.select(easy_conditions, easy_labels)\n",
    "nan_football_df_noNone"
   ],
   "id": "143b539d11ec3c73",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.668822Z",
     "start_time": "2025-02-04T10:45:28.617036Z"
    }
   },
   "cell_type": "code",
   "source": "nan_football_df_noNone['label'].mean()",
   "id": "f300485c34204a70",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.713436Z",
     "start_time": "2025-02-04T10:45:28.669825Z"
    }
   },
   "cell_type": "code",
   "source": "nan_football_df_noNone['easy_label'].mean()",
   "id": "de705b485595798e",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ad42e459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.764485Z",
     "start_time": "2025-02-04T10:45:28.714087Z"
    }
   },
   "source": [
    "# resize shape\n",
    "football_df.shape[0] - nan_football_df_noNone.shape[0]"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "42864535",
   "metadata": {},
   "source": [
    "### 2.2 Feature Encoding <br>\n",
    "* $\\phi(Date)$ $\\Rightarrow$ one column for *year*, second column for *month*, third column for *day of year*\n",
    "* One hot encode Division, Home and Away Teams\n",
    "* Label encode Full Time Result (Win/Draw/Loss)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b5bb61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.806342Z",
     "start_time": "2025-02-04T10:45:28.765491Z"
    }
   },
   "source": [
    "feats = nan_mask\n",
    "feats.append('easy_label')"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.862835Z",
     "start_time": "2025-02-04T10:45:28.807347Z"
    }
   },
   "cell_type": "code",
   "source": "nan_football_df_noNone",
   "id": "9919d74193a28304",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:28.917482Z",
     "start_time": "2025-02-04T10:45:28.863840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_df_feat = nan_football_df_noNone.copy()[feats]\n",
    "learning_df_feat"
   ],
   "id": "5213f7b7293d7cc0",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fe16f1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:30.090228Z",
     "start_time": "2025-02-04T10:45:28.918486Z"
    }
   },
   "source": [
    "learning_df_feat.reset_index(inplace=True, drop=True)\n",
    "# 保存文件作为历史文件\n",
    "learning_df_feat.to_csv('.\\prediction_data/history_data.csv', index=False, encoding='utf-8-sig')\n",
    "learning_df_feat"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "15884417",
   "metadata": {},
   "source": [
    "**2.2.1 Division and Home/Away Team Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "id": "913c0088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:31.876774Z",
     "start_time": "2025-02-04T10:45:30.092738Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "div_encoder = OneHotEncoder()\n",
    "home_encoder = OneHotEncoder()\n",
    "away_encoder = OneHotEncoder()"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bc739d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:31.991445Z",
     "start_time": "2025-02-04T10:45:31.877778Z"
    }
   },
   "source": [
    "onehot_div = div_encoder.fit_transform(learning_df_feat.Div.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_div_df = pd.DataFrame(onehot_div, columns = [\"Div \"+str(int(i)) for i in range(onehot_div.shape[1])])\n",
    "\n",
    "onehot_home = home_encoder.fit_transform(learning_df_feat.HomeTeam.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_home_df = pd.DataFrame(onehot_home, columns = ['HomeTeam ' + str(int(i)) for i in np.arange(onehot_home.shape[1])])\n",
    "\n",
    "onehot_away = away_encoder.fit_transform(learning_df_feat.AwayTeam.values.reshape(-1,1)).toarray().astype(int)\n",
    "onehot_away_df = pd.DataFrame(onehot_away, columns = ['AwayTeam ' + str(int(i)) for i in np.arange(onehot_away.shape[1])])"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.088524Z",
     "start_time": "2025-02-04T10:45:31.992949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存编码器到本地\n",
    "joblib.dump(div_encoder, 'div_encoder.pkl')\n",
    "joblib.dump(home_encoder, 'home_encoder.pkl')\n",
    "joblib.dump(away_encoder, 'away_encoder.pkl')"
   ],
   "id": "afe5dd460928770d",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f8444147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.241261Z",
     "start_time": "2025-02-04T10:45:32.090119Z"
    }
   },
   "source": [
    "learning_df_div = pd.concat([learning_df_feat, onehot_div_df, onehot_home_df, onehot_away_df], axis = 1)\n",
    "learning_df_div.drop(columns = ['Div'], inplace = True)"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "321f2f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.316409Z",
     "start_time": "2025-02-04T10:45:32.244768Z"
    }
   },
   "source": "learning_df_div",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0fefa3",
   "metadata": {},
   "source": [
    "**2.2.2 Full Time Result Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "id": "f9442a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.377481Z",
     "start_time": "2025-02-04T10:45:32.321414Z"
    }
   },
   "source": [
    "target_encoder = LabelEncoder()\n",
    "learning_df_div['Result'] = target_encoder.fit_transform(learning_df_div.easy_label) "
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "18c1cb41",
   "metadata": {},
   "source": [
    "**2.2.3 Date Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5dfc529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.486403Z",
     "start_time": "2025-02-04T10:45:32.377481Z"
    }
   },
   "source": [
    "learning_df_div['Year'] = pd.DatetimeIndex(learning_df_div.Date).year\n",
    "\n",
    "learning_df_div['Month'] = pd.DatetimeIndex(learning_df_div.Date).month\n",
    "learning_df_div['Sin_Month'] = np.sin(2*np.pi*learning_df_div.Month/12)\n",
    "learning_df_div['Cos_Month'] = np.cos(2*np.pi*learning_df_div.Month/12)\n",
    "\n",
    "learning_df_div['DayofYear'] = pd.DatetimeIndex(learning_df_div.Date).dayofyear\n",
    "learning_df_div['Sin_Day'] = np.sin(2*np.pi*learning_df_div.DayofYear/365)\n",
    "learning_df_div['Cos_Day'] = np.cos(2*np.pi*learning_df_div.DayofYear/365)\n",
    "\n",
    "# 注意 inplace是在原始frame修改，返回值是Nonetype\n",
    "# learning_df = learning_df_div.drop(columns = ['Date','Month'], inplace = True)\n",
    "learning_df = learning_df_div.drop(columns = ['Date','Month'])\n",
    "# learning_df.drop(columns = ['Date'], inplace = True)"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.564436Z",
     "start_time": "2025-02-04T10:45:32.487027Z"
    }
   },
   "cell_type": "code",
   "source": "learning_df",
   "id": "7e7bc241",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.636053Z",
     "start_time": "2025-02-04T10:45:32.565437Z"
    }
   },
   "cell_type": "code",
   "source": "# For Test\n",
   "id": "866fbac3337d0235",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b14da74e",
   "metadata": {},
   "source": [
    "### 2.3 Feature Engineering <br>\n",
    "* $\\phi(x)$ feature transformation $\\Rightarrow$ last match result, win/loss streak to date, wins to season date\n",
    "* $\\phi(x)$ feature engineering $\\Rightarrow$ average the home, away, and draw odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843342cb",
   "metadata": {},
   "source": [
    "**2.3.1 Last Match Result** <br>\n",
    "Indicate the result from the last match played between both teams"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 定义一个函数来计算两队之间上一场比赛的结果\n",
    "def compute_last_matches(df):\n",
    "    \n",
    "    unique_matchups = list(set((list(zip(df.HomeTeam, df.AwayTeam)))))\n",
    "    df['Last Match Result'] = np.nan\n",
    "    for home, away in unique_matchups:\n",
    "        matchup_df = df[(df.HomeTeam == home) & (df.AwayTeam == away)]\n",
    "        # 使用 shift(1) 方法将 FTR（全场比赛结果）列中的数据向下移动一行，这样每行的 last_match_result 将对应于这两队之前的一场比赛的结果。fill_value='Na' 确保了数据移动后空出的位置填充为 'Na'。\n",
    "        # last_match_result = matchup_df.FTR.shift(1, fill_value='Na')\n",
    "        last_match_result = matchup_df.easy_label.shift(1, fill_value='Na')\n",
    "        df.loc[matchup_df.index, 'Last Match Result'] = last_match_result\n",
    "        \n",
    "    lmr_encoder = LabelEncoder()\n",
    "    df['Last Match Result'] = lmr_encoder.fit_transform(df['Last Match Result'])\n",
    "    df.drop(columns = ['easy_label'], inplace = True)\n",
    "    return df"
   ],
   "id": "4b25dbdd59e2d17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:32.692814Z",
     "start_time": "2025-02-04T10:45:32.637048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_last_n_matches(df, n=5):\n",
    "    unique_matchups = list(set(zip(df.HomeTeam, df.AwayTeam)))\n",
    "    df['Last 5 Match Results'] = np.nan  # 新增一列用于存储过去 5 场比赛的结果\n",
    "    \n",
    "    for home, away in unique_matchups:\n",
    "        matchup_df = df[(df.HomeTeam == home) & (df.AwayTeam == away)]\n",
    "        \n",
    "        # 获取过去 n 场比赛的结果\n",
    "        # last_n_results = [matchup_df.FTR.shift(i, fill_value='Na') for i in range(1, n+1)]\n",
    "        last_n_results = [matchup_df.easy_label.shift(i, fill_value='Na') for i in range(1, n+1)]\n",
    "        \n",
    "        # 将计算得到的过去 n 场比赛的结果合并为一个字符串或列表，取决于需求\n",
    "        # 这里使用字符串形式：'result1/result2/...'\n",
    "        matchup_df['Last 5 Match Results'] = pd.DataFrame(last_n_results).T.apply(lambda x: '/'.join(x), axis=1)\n",
    "        \n",
    "        # 将计算得到的结果更新回原始 df 中\n",
    "        df.loc[matchup_df.index, 'Last 5 Match Results'] = matchup_df['Last 5 Match Results']\n",
    "    \n",
    "    # 对 Last 5 Match Results 列进行标签编码\n",
    "    lmr_encoder = LabelEncoder()\n",
    "    df['Last 5 Match Results'] = lmr_encoder.fit_transform(df['Last 5 Match Results'])\n",
    "    \n",
    "    # 删除原始的 FTR 列\n",
    "    df.drop(columns=['easy_label'], inplace=True)\n",
    "    \n",
    "    return df\n"
   ],
   "id": "bee90a274731b07e",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "751bdc97",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:55.944162Z",
     "start_time": "2025-02-04T10:45:32.694327Z"
    }
   },
   "source": [
    "# 定义一个函数来计算两队之间上一场比赛的结果\n",
    "def compute_last_matches(df):\n",
    "    \n",
    "    unique_matchups = list(set((list(zip(df.HomeTeam, df.AwayTeam)))))\n",
    "    df['Last Match Result'] = np.nan\n",
    "    for home, away in unique_matchups:\n",
    "        matchup_df = df[(df.HomeTeam == home) & (df.AwayTeam == away)]\n",
    "        # 使用 shift(1) 方法将 FTR（全场比赛结果）列中的数据向下移动一行，这样每行的 last_match_result 将对应于这两队之前的一场比赛的结果。fill_value='Na' 确保了数据移动后空出的位置填充为 'Na'。\n",
    "        # last_match_result = matchup_df.FTR.shift(1, fill_value='Na')\n",
    "        last_match_result = matchup_df.easy_label.shift(1, fill_value=3)\n",
    "        df.loc[matchup_df.index, 'Last Match Result'] = last_match_result\n",
    "        \n",
    "    lmr_encoder = LabelEncoder()\n",
    "    df['Last Match Result'] = lmr_encoder.fit_transform(df['Last Match Result'])\n",
    "    df.drop(columns = ['easy_label'], inplace = True)\n",
    "    return df\n",
    "learning_df = compute_last_matches(learning_df)\n",
    "# learning_df.drop(columns = ['FTR'], inplace = True)"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8ff554cf",
   "metadata": {},
   "source": [
    "**2.3.2 Home and Away Win/Loss Streak** <br>\n",
    "Important note about this feature: the win/loss streak is the teams *home* and *away* win streak, *not* its ***consecutive*** win/loss streak."
   ]
  },
  {
   "cell_type": "code",
   "id": "41f1fcc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:55.962179Z",
     "start_time": "2025-02-04T10:45:55.945166Z"
    }
   },
   "source": [
    "# https://stackoverflow.com/questions/52976336/compute-winning-streak-with-pandas\n",
    "# https://joshdevlin.com/blog/calculate-streaks-in-pandas/"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4658caa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.094020Z",
     "start_time": "2025-02-04T10:45:55.963183Z"
    }
   },
   "source": [
    "def compute_winstreak(df):\n",
    "    \n",
    "    years = df.Year.unique()\n",
    "    df_lst = []    \n",
    "    for year in years:\n",
    "        \n",
    "        year_df = df[df.Year == year]\n",
    "        year_df['HomeWin'] = year_df.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "        year_df['AwayWin'] = year_df.Result.replace([0, 1, 2], [1, 0, 0])\n",
    "        year_df['HomeWinStreak'] = None\n",
    "        year_df['AwayWinStreak'] = None\n",
    "        \n",
    "        hometeams = year_df.HomeTeam.unique()\n",
    "        awayteams = year_df.AwayTeam.unique()\n",
    "        \n",
    "        for team in hometeams:\n",
    "            team_df = year_df[(year_df.HomeTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_grouper = (team_df.HomeWin != team_df.HomeWin.shift()).cumsum()\n",
    "            team_df['HomeWinStreak'] = team_df[['HomeWin']].groupby(team_grouper).cumsum()\n",
    "            team_df.loc[team_df.HomeWinStreak >0, 'HomeWinStreak'] -= 1\n",
    "            year_df.loc[team_df.index, 'HomeWinStreak'] = team_df.HomeWinStreak\n",
    "            \n",
    "        for team in awayteams:\n",
    "            team_df = year_df[(year_df.AwayTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_grouper = (team_df.AwayWin != team_df.AwayWin.shift()).cumsum()\n",
    "            team_df['AwayWinStreak'] = team_df[['AwayWin']].groupby(team_grouper).cumsum()\n",
    "            team_df.loc[team_df.AwayWinStreak >0, 'AwayWinStreak'] -= 1\n",
    "            year_df.loc[team_df.index, 'AwayWinStreak'] = team_df.AwayWinStreak\n",
    "            \n",
    "        df_lst.append(year_df)\n",
    "        \n",
    "    return pd.concat(df_lst, axis = 0).drop(columns = ['HomeWin', 'AwayWin'])#,'DayofYear'])"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "aca53647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.154012Z",
     "start_time": "2025-02-04T10:45:56.095024Z"
    }
   },
   "source": [
    "# learning_df = compute_winstreak(learning_df)\n",
    "learning_df"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "94e1c235",
   "metadata": {},
   "source": [
    "**2.3.4 Season Home/Away Wins to Date** <br>\n",
    "Indicate the number of wins for a team as home and away to date within current season"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "toy = learning_df[(learning_df.Year == 2010) & (learning_df.HomeTeam == 'Barcelona')][['HomeTeam', 'AwayTeam', 'Result']]\n",
    "toy['HomeWin'] = toy.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "toy['HomeWinsToDate'] = toy.HomeWin.cumsum()"
   ],
   "id": "2e5f10c06aee07e5"
  },
  {
   "cell_type": "code",
   "id": "885dc94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.213425Z",
     "start_time": "2025-02-04T10:45:56.157016Z"
    }
   },
   "source": [
    "def compute_winstodate(df):\n",
    "    \n",
    "    years = df.Year.unique()\n",
    "    df_lst = []    \n",
    "    for year in years:\n",
    "        \n",
    "        year_df = df[df.Year == year]\n",
    "        year_df['HomeWin'] = year_df.Result.replace([0, 1, 2], [0, 0, 1])\n",
    "        year_df['AwayWin'] = year_df.Result.replace([0, 1, 2], [1, 0, 0])\n",
    "        year_df['HomeWinsToDate'] = None\n",
    "        year_df['AwayWinsToDate'] = None\n",
    "        \n",
    "        hometeams = year_df.HomeTeam.unique()\n",
    "        awayteams = year_df.AwayTeam.unique()\n",
    "        \n",
    "        for team in hometeams:\n",
    "            team_df = year_df[(year_df.HomeTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "\n",
    "            team_df['HomeWinsToDate'] = team_df.HomeWin.cumsum()\n",
    "            year_df.loc[team_df.index, 'HomeWinsToDate'] = team_df.HomeWinsToDate\n",
    "            \n",
    "        for team in awayteams:\n",
    "            team_df = year_df[(year_df.AwayTeam == team)]\n",
    "            team_df = team_df.sort_values(['Year', 'DayofYear'], ascending = (True, True))\n",
    "            \n",
    "            team_df['AwayWinsToDate'] = team_df.AwayWin.cumsum()\n",
    "            year_df.loc[team_df.index, 'AwayWinsToDate'] = team_df.AwayWinsToDate\n",
    "            \n",
    "        df_lst.append(year_df)\n",
    "        \n",
    "    return pd.concat(df_lst, axis = 0).drop(columns = ['HomeWin', 'AwayWin','DayofYear'])"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b60fbbf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.269534Z",
     "start_time": "2025-02-04T10:45:56.214431Z"
    }
   },
   "source": [
    "# learning_df = compute_winstodate(learning_df)\n",
    "learning_df.drop(columns = ['HomeTeam', 'AwayTeam'], inplace = True)"
   ],
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.341357Z",
     "start_time": "2025-02-04T10:45:56.269534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# learning_df\n",
    "learning_df"
   ],
   "id": "b23f5c1f7a05744b",
   "execution_count": 39,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.733054Z",
     "start_time": "2025-02-04T10:45:56.342361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存为pkl文件\n",
    "learning_df.to_pickle('E:/Data/PKL/learning_df.pkl')"
   ],
   "id": "749b75afd7a2bc77",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "36c2496f",
   "metadata": {},
   "source": [
    "**2.3.5 Website Odds** <br>\n",
    "The `betting odds` recorded by various betting websites offer insight into sentiment surrounding the outcome of a particular game. "
   ]
  },
  {
   "cell_type": "code",
   "id": "1efc8290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.807895Z",
     "start_time": "2025-02-04T10:45:56.735058Z"
    }
   },
   "source": [
    "# betting_feats = ['B365H', 'B365D', 'B365A', 'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA', \"AHh\", \"B365AHH\", \"B365AHA\"]\n",
    "betting_feats = ['B365H', 'B365D', 'B365A']\n",
    "betting_feats"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "031548ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.869233Z",
     "start_time": "2025-02-04T10:45:56.808900Z"
    }
   },
   "source": [
    "def compute_meanodds(df, betting_feats):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    home_odds = []\n",
    "    away_odds = []\n",
    "    draw_odds = []\n",
    "    for odd in betting_feats:\n",
    "        odd_type = odd[-1]\n",
    "        if odd_type == 'H':\n",
    "            home_odds.append(odd)\n",
    "        elif odd_type == 'A':\n",
    "            away_odds.append(odd)\n",
    "        else:\n",
    "            draw_odds.append(odd)\n",
    "    avg_home_odds = df[home_odds].mean(axis=1)\n",
    "    avg_away_odds = df[away_odds].mean(axis=1)\n",
    "    avg_draw_odds = df[draw_odds].mean(axis=1)\n",
    "    \n",
    "    ordered_cols = ['HomeOdds', 'AwayOdds', 'DrawOdds'] + df.columns.tolist()\n",
    "    \n",
    "    df['HomeOdds'] = avg_home_odds\n",
    "    df['AwayOdds'] = avg_away_odds\n",
    "    df['DrawOdds'] = avg_draw_odds\n",
    "    \n",
    "    return df[ordered_cols]"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "08e0a28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:56.975106Z",
     "start_time": "2025-02-04T10:45:56.875073Z"
    }
   },
   "source": [
    "learning_df = compute_meanodds(learning_df, betting_feats)"
   ],
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0e4768c8",
   "metadata": {},
   "source": [
    "### 2.4 Peek @ Learning DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "b54348f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.099491Z",
     "start_time": "2025-02-04T10:45:56.977614Z"
    }
   },
   "source": [
    "learning_df"
   ],
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.195927Z",
     "start_time": "2025-02-04T10:45:57.100495Z"
    }
   },
   "cell_type": "code",
   "source": "learning_df.drop(columns = ['WHH', 'WHD', 'WHA', 'HomeOdds', 'AwayOdds', 'DrawOdds', 'FTHG', 'FTAG'], inplace = True)",
   "id": "228a748b486ff190",
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7b46d936",
   "metadata": {},
   "source": [
    "# 3. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e10788",
   "metadata": {},
   "source": [
    "* Establish a baseline Logistic Regression model fit over the entire learning dataframe without special regard to *division* and *team*. \n",
    "* Train model over 16 seasons, and predict for the remaining 3 seasons (approximate 80-20 split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ddd44e",
   "metadata": {},
   "source": [
    "### 3.1 Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "id": "a82f4a6b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.298159Z",
     "start_time": "2025-02-04T10:45:57.196927Z"
    }
   },
   "source": [
    "split = 0.80\n",
    "no_seasons = 20\n",
    "\n",
    "print('No. seasons to train over: ' + str(round(split*no_seasons)))"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f22ecde1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.379122Z",
     "start_time": "2025-02-04T10:45:57.299167Z"
    }
   },
   "source": "X, y = learning_df.loc[:, learning_df.columns != 'Result'], learning_df[['Result']]",
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "60373664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.454589Z",
     "start_time": "2025-02-04T10:45:57.379630Z"
    }
   },
   "source": [
    "# full_feat = ['HomeWinStreak','AwayWinStreak','HomeWinsToDate', 'AwayWinsToDate', 'Last Match Result',\n",
    "#              'HomeTeamELO', 'AwayTeamELO', 'HomeOdds', 'AwayOdds', 'DrawOdds'] + betting_feats\n",
    "\n",
    "# exclude_feats = ['HomeWinsToDate', 'AwayWinsToDate', 'Last Match Result'] "
   ],
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1db1f4fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.565761Z",
     "start_time": "2025-02-04T10:45:57.463203Z"
    }
   },
   "source": [
    "# X = X[X.columns[~X.columns.isin(exclude_feats)]]\n",
    "# X"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4c621fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.704015Z",
     "start_time": "2025-02-04T10:45:57.572764Z"
    }
   },
   "source": [
    "X"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.760044Z",
     "start_time": "2025-02-04T10:45:57.707019Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "232473f400896cfa",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.839453Z",
     "start_time": "2025-02-04T10:45:57.761051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "split_year = 2023\n",
    "start_year = split_year - 10"
   ],
   "id": "44dc55d09c257a7d",
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0e361977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.924851Z",
     "start_time": "2025-02-04T10:45:57.840460Z"
    }
   },
   "source": [
    "# 切分训练集和测试集\n",
    "xTr, xTe = X[(X.Year <= split_year) & (X.Year >= start_year)], X[X.Year > split_year]\n",
    "yTr, yTe = y.loc[xTr.index, :], y.loc[xTe.index, :]"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Normalization <br>\n",
    "Following our various feature transformations and development, we arrived to a sparse dataframe with the exception of a few features(*Year, DayofYear*). It will be important to *normalize* these features as they are in gross magnitudes compared to the remaining features. During model training, having dominating features (in scale relative to others) can be dangerous as the weight updates may mistakengly favor these larger-scale features because it will have the largest influence on the target output. "
   ],
   "id": "50636cdc8bb898d6"
  },
  {
   "cell_type": "code",
   "id": "a72d269a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:57.986901Z",
     "start_time": "2025-02-04T10:45:57.926853Z"
    }
   },
   "source": [
    "# minmax_scaler.fit_transform()：这个方法首先拟合数据，即计算数据的最小值和最大值，这些值用于后续的缩放。然后，它将这些参数用于转换数据，将原始数据缩放到0和1之间。\n",
    "# minmax_scaler.transform()：这个方法使用在训练数据上计算得到的最小值和最大值来转换测试数据。这确保了训练数据和测试数据使用相同的缩放标准。\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "xTr.loc[:, ['Year']] = minmax_scaler.fit_transform(xTr.loc[:, ['Year']])\n",
    "xTe.loc[:, ['Year']] = minmax_scaler.transform(xTe.loc[:, ['Year']])"
   ],
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "11ee9c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:58.070520Z",
     "start_time": "2025-02-04T10:45:57.987904Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "# to_scale = ['HomeWinStreak','AwayWinStreak','HomeWinsToDate', 'AwayWinsToDate', 'HomeTeamELO', 'AwayTeamELO', 'HomeOdds', 'AwayOdds', 'DrawOdds'] + betting_feats\n",
    "to_scale = ['HomeTeamELO', 'AwayTeamELO'] + betting_feats\n",
    "\n",
    "xTr.loc[:, to_scale] = std_scaler.fit_transform(xTr.loc[:, to_scale])\n",
    "xTe.loc[:, to_scale] = std_scaler.transform(xTe.loc[:, to_scale])"
   ],
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "76792bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:58.155110Z",
     "start_time": "2025-02-04T10:45:58.071523Z"
    }
   },
   "source": [
    "xTr"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4696b592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:58.247372Z",
     "start_time": "2025-02-04T10:45:58.156111Z"
    }
   },
   "source": [
    "xTe"
   ],
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8b0abe45",
   "metadata": {},
   "source": [
    "### 3.3 HomeWins Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8002824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:45:59.933899Z",
     "start_time": "2025-02-04T10:45:58.249449Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:46:00.065390Z",
     "start_time": "2025-02-04T10:45:59.934899Z"
    }
   },
   "cell_type": "code",
   "source": "xTr.shape",
   "id": "bdd8d4925bb687b9",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:46:00.180291Z",
     "start_time": "2025-02-04T10:46:00.066444Z"
    }
   },
   "cell_type": "code",
   "source": "xTe.shape",
   "id": "53f767c6fd6ea837",
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f13115e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:46:00.300467Z",
     "start_time": "2025-02-04T10:46:00.181314Z"
    }
   },
   "source": [
    "# training score\n",
    "baseline_Tr = np.full((xTr.shape[0], 1), 2) \n",
    "accuracy_score(yTr.Result.values, baseline_Tr.ravel())"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "16d2cf5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:46:00.406678Z",
     "start_time": "2025-02-04T10:46:00.302508Z"
    }
   },
   "source": [
    "# testing score\n",
    "baseline_preds_Te = np.full((xTe.shape[0]  , 1), 2) #predicts home wins all the time\n",
    "accuracy_score(yTe.Result.values, baseline_preds_Te.ravel())"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dff87ca8",
   "metadata": {},
   "source": [
    "### 3.4 Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03fdd6",
   "metadata": {},
   "source": [
    "**3.4.1** $l2$ Regularized"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c5f52f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:47:45.561289Z",
     "start_time": "2025-02-04T10:46:00.407182Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l2_lr = LogisticRegression(max_iter = 10000, n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "54140ce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:47:45.635876Z",
     "start_time": "2025-02-04T10:47:45.562304Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l2_lr.predict(xTr))"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8c59602e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:47:45.655842Z",
     "start_time": "2025-02-04T10:47:45.636881Z"
    }
   },
   "source": [
    "# testing score\n",
    "lr_preds = l2_lr.predict(xTe)\n",
    "accuracy_score(yTe.Result.values, lr_preds)"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8adcb166",
   "metadata": {},
   "source": [
    "**3.4.1** $l2$ Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "3009cb8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:50:11.080674Z",
     "start_time": "2025-02-04T10:47:45.656846Z"
    }
   },
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "logistic_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "# logistic_randsearch = RandomizedSearchCV(estimator=LogisticRegression(max_iter=10000),\n",
    "#                                          param_distributions=logistic_params,\n",
    "logistic_randsearch = GridSearchCV(estimator=LogisticRegression(max_iter=10000),\n",
    "                                         param_grid=logistic_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=1,\n",
    "                                         cv=5,\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "logistic_rand_results = logistic_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (logistic_rand_results.best_score_, logistic_rand_results.best_params_))"
   ],
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a9231529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:50:11.092416Z",
     "start_time": "2025-02-04T10:50:11.081191Z"
    }
   },
   "source": [
    "l2_rs = logistic_rand_results.best_estimator_"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9197a0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:50:11.146552Z",
     "start_time": "2025-02-04T10:50:11.092416Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l2_rs.predict(xTr))"
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5c45f431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:50:11.168099Z",
     "start_time": "2025-02-04T10:50:11.147559Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, l2_rs.predict(xTe))"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "febcc06f",
   "metadata": {},
   "source": [
    "**3.4.4** $l1$ Regularized"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9502351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:00:12.969990Z",
     "start_time": "2025-02-04T10:50:11.168603Z"
    }
   },
   "source": [
    "l1_lr = LogisticRegression(penalty='l1', solver='saga', max_iter = 10000, n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "82d75648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:00:13.008932Z",
     "start_time": "2025-02-04T11:00:12.970493Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l1_lr.predict(xTr))"
   ],
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4faea9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:00:13.027385Z",
     "start_time": "2025-02-04T11:00:13.008932Z"
    }
   },
   "source": [
    "# testing score\n",
    "l1_preds = l1_lr.predict(xTe)\n",
    "accuracy_score(yTe.Result.values, l1_preds)"
   ],
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "445dcdb4",
   "metadata": {},
   "source": [
    "**3.4.5** Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "3314235e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:19:50.205853Z",
     "start_time": "2025-02-04T11:00:13.028392Z"
    }
   },
   "source": [
    "l1_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "# l1_randsearch = RandomizedSearchCV(estimator=LogisticRegression(penalty='l1',solver='saga', max_iter=10000),\n",
    "#                                          param_distributions=l1_params,\n",
    "l1_randsearch = GridSearchCV(estimator=LogisticRegression(penalty='l1',solver='saga', max_iter=10000),\n",
    "                                         param_grid=l1_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=1,\n",
    "                                         n_jobs=-1,\n",
    "                                         cv=5)\n",
    "\n",
    "l1_rand_results = l1_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (l1_rand_results.best_score_, l1_rand_results.best_params_))"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f4607e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:19:50.215321Z",
     "start_time": "2025-02-04T11:19:50.206860Z"
    }
   },
   "source": [
    "l1_rs = l1_randsearch.best_estimator_ #LogisticRegression(C=0.10, solver='saga', max_iter=10000).fit(xTr, yTr.values.ravel())#"
   ],
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4895d05a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:19:50.260976Z",
     "start_time": "2025-02-04T11:19:50.216327Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, l1_rs.predict(xTr))"
   ],
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7016a84c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:19:50.280110Z",
     "start_time": "2025-02-04T11:19:50.261981Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, l1_rs.predict(xTe))"
   ],
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8b988c26",
   "metadata": {},
   "source": [
    "### 3.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "id": "0f4908d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:21:18.616911Z",
     "start_time": "2025-02-04T11:19:50.281118Z"
    }
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(max_iter=100000).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1a18a45a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:22:59.922002Z",
     "start_time": "2025-02-04T11:21:18.617914Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, svm.predict(xTr))"
   ],
   "execution_count": 78,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7311630d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:23:09.700719Z",
     "start_time": "2025-02-04T11:22:59.922002Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, svm.predict(xTe))"
   ],
   "execution_count": 79,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:23:09.765091Z",
     "start_time": "2025-02-04T11:23:09.701725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "local_time = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "dump(svm, f'./sklearn_svm_{local_time}.joblib')"
   ],
   "id": "8aa91dd154b17f52",
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f00bed",
   "metadata": {},
   "source": [
    "**3.5.2** Penalty Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b998f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:33:07.728412Z",
     "start_time": "2025-02-04T11:23:09.766098Z"
    }
   },
   "source": [
    "svm_params = {'C':[0.001,0.01,0.10]}\n",
    "\n",
    "# svm_randsearch = RandomizedSearchCV(estimator=SVC(max_iter=100000),\n",
    "#                                          param_distributions=svm_params,\n",
    "svm_randsearch = GridSearchCV(estimator=SVC(max_iter=100000),\n",
    "                                         param_grid=svm_params,\n",
    "                                         scoring='accuracy',\n",
    "                                         verbose=2,\n",
    "                                         cv=5,\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "svm_rand_results = svm_randsearch.fit(xTr, yTr.values.ravel())\n",
    "print(\"Best: %f using %s\" % (svm_rand_results.best_score_, svm_rand_results.best_params_))"
   ],
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7f9627ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:33:07.737696Z",
     "start_time": "2025-02-04T11:33:07.729418Z"
    }
   },
   "source": [
    "svm_rs = svm_rand_results.best_estimator_"
   ],
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e32e6caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:34:49.039026Z",
     "start_time": "2025-02-04T11:33:07.738706Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, svm_rs.predict(xTr))"
   ],
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e88837b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:34:58.830845Z",
     "start_time": "2025-02-04T11:34:49.040030Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, svm_rs.predict(xTe))"
   ],
   "execution_count": 84,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:34:58.910542Z",
     "start_time": "2025-02-04T11:34:58.839806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "local_time = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "dump(svm_randsearch, f'./sklearn_svm_randsearch_{local_time}.joblib')"
   ],
   "id": "600612029a6f8e34",
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "edee8858",
   "metadata": {},
   "source": [
    "### 3.6 Simple Neural Network ####"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0505f91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.541787Z",
     "start_time": "2025-02-04T12:45:27.687192Z"
    }
   },
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128,32),\n",
    "                    activation='relu',\n",
    "                    batch_size=512,\n",
    "                    max_iter=1000,\n",
    "                    learning_rate_init=1e-4,\n",
    "                    early_stopping=False,\n",
    "                    alpha=1e-3,\n",
    "                   ).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5ca78c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.613973Z",
     "start_time": "2025-02-04T12:48:08.542799Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, mlp.predict(xTr))"
   ],
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "aa884592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.635522Z",
     "start_time": "2025-02-04T12:48:08.613973Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, mlp.predict(xTe))"
   ],
   "execution_count": 104,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.660646Z",
     "start_time": "2025-02-04T12:48:08.636528Z"
    }
   },
   "cell_type": "code",
   "source": "xTr",
   "id": "f3b1aae2279970a7",
   "execution_count": 105,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.673516Z",
     "start_time": "2025-02-04T12:48:08.661656Z"
    }
   },
   "cell_type": "code",
   "source": "yTr",
   "id": "e4dd2c1c61d1079c",
   "execution_count": 106,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.695072Z",
     "start_time": "2025-02-04T12:48:08.674527Z"
    }
   },
   "cell_type": "code",
   "source": "xTe",
   "id": "b2b865f37b49cf07",
   "execution_count": 107,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.709352Z",
     "start_time": "2025-02-04T12:48:08.695648Z"
    }
   },
   "cell_type": "code",
   "source": "yTe",
   "id": "a695d991d7cb690f",
   "execution_count": 108,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:08.734684Z",
     "start_time": "2025-02-04T12:48:08.710359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predict_val = mlp.predict(xTe)\n",
    "series_pre = pd.Series(predict_val, name='Predicted')\n",
    "compare_result = pd.concat([series_pre, yTe.reset_index()], axis=1)\n",
    "compare_result"
   ],
   "id": "75000857933fee73",
   "execution_count": 109,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:48:09.640890Z",
     "start_time": "2025-02-04T12:48:08.735688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "result_subset = compare_result.tail(200)\n",
    "plt.figure(figsize=(10,10))\n",
    "result_subset.plot(x='index', y=['Predicted', 'Result'], kind='line')\n",
    "plt.title(\"Prediction vs Real\")\n",
    "plt.show()"
   ],
   "id": "bf60fe066e7da7b",
   "execution_count": 110,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 保存模型",
   "id": "de0d8edbd57b1b47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:38:12.914296Z",
     "start_time": "2025-02-04T11:38:12.870138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "local_time = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "dump(mlp, f'./sklearn_mlp_{local_time}.joblib')"
   ],
   "id": "3112f4279bcb97e0",
   "execution_count": 95,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:38:12.935611Z",
     "start_time": "2025-02-04T11:38:12.915301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ### 加载模型\n",
    "# # model_name = 'sklearn_mlp_' + local_time + '.joblib'\n",
    "# model_name = './' + 'sklearn_mlp_2025_01_21_22_41_15.joblib'\n",
    "# mlp = load(model_name)"
   ],
   "id": "b01de6170bcd5bc2",
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4656a5",
   "metadata": {},
   "source": [
    "### 3.7 Stacked Classifier ###"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a2f0890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:38:12.950658Z",
     "start_time": "2025-02-04T11:38:12.936617Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ],
   "execution_count": 97,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "94e15eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:43:35.403585Z",
     "start_time": "2025-02-04T11:38:12.951203Z"
    }
   },
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "stacked_clf = StackingClassifier(estimators=[('svm', SVC(max_iter=100000)), ('logistic', LogisticRegression(C=0.01, max_iter=10000))],\n",
    "                                final_estimator=LogisticRegression(max_iter=10000),\n",
    "                                n_jobs=-1).fit(xTr, yTr.values.ravel())"
   ],
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b22e6db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:45:20.829522Z",
     "start_time": "2025-02-04T11:43:35.404626Z"
    }
   },
   "source": [
    "# training score\n",
    "accuracy_score(yTr.Result.values, stacked_clf.predict(xTr))"
   ],
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7a57d164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:45:31.184302Z",
     "start_time": "2025-02-04T11:45:20.830527Z"
    }
   },
   "source": [
    "# testing score\n",
    "accuracy_score(yTe.Result.values, stacked_clf.predict(xTe))"
   ],
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e90e8cae",
   "metadata": {},
   "source": [
    "## 4. Result Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "id": "0d4a4507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:45:31.195499Z",
     "start_time": "2025-02-04T11:45:31.185308Z"
    }
   },
   "source": [
    "## TODO: breakdown results across divisions and/or teams; i.e., see how model performs individually at subgroups"
   ],
   "execution_count": 101,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a10a069c",
   "metadata": {},
   "source": [
    "## 5. Scrap Code ##"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "barcelona_df = learning_df[(learning_df['HomeTeam 17'] == 1) | (learning_df['AwayTeam 17'] == 1)]\n",
    "barcelona_df"
   ],
   "id": "341484a2986d9403"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "bxTr = xTr[(xTr['HomeTeam 17'] == 1) | (xTr['AwayTeam 17'] == 1)]\n",
    "bxTe = xTe[(xTe['HomeTeam 17'] == 1) | (xTe['AwayTeam 17'] == 1)]"
   ],
   "id": "6aea308dbcad2c24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "byTr, byTe = yTr.loc[bxTr.index,:], yTe.loc[bxTe.index,:]",
   "id": "223dcbea35812a00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# training score\n",
    "accuracy_score(byTr, l1_lr.predict(bxTr))"
   ],
   "id": "102a70b23352602a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# testing score\n",
    "accuracy_score(byTe, l1_lr.predict(bxTe))"
   ],
   "id": "9dfe0d98c2fbc4b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# training score\n",
    "accuracy_score(byTr, l2_lr.predict(bxTr))"
   ],
   "id": "d7f97b59cf02a6fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# testing score\n",
    "accuracy_score(byTe, l2_lr.predict(bxTe))"
   ],
   "id": "81b01d50de577c4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Pytorch MLP ##",
   "id": "1a9d44ed88b506d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "type(xTr)",
   "id": "d1b18995e0514e50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "xTr.shape",
   "id": "6dee2e916677fa2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ],
   "id": "93924d1ff0c31b78"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.randn(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 应用注意力权重\n",
    "        weights = F.softmax(self.attention_weights, dim=0)\n",
    "        # 加权求和\n",
    "        x = x * weights\n",
    "        return x\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=xTr.shape[1], out_features=512)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=512)\n",
    "        self.attention = Attention(512)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=128)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=128)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=32)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=32)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features=32, out_features=3)  # 输出层改为3，对应三个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(torch.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.attention(x)\n",
    "        x = self.dropout2(torch.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout3(torch.relu(self.bn3(self.fc3(x))))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "xTr_scaled = scaler.fit_transform(xTr)\n",
    "xTr_tensor = torch.tensor(xTr_scaled, dtype=torch.float32).to(device)\n",
    "yTr_tensor = torch.tensor(yTr.values.ravel(), dtype=torch.long).to(device)\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset = TensorDataset(xTr_tensor, yTr_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# 创建模型实例\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "train_start = time.time()\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(500):  # 假设训练200个epoch\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # 清除之前的梯度\n",
    "\n",
    "        outputs = model(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)  # 累计损失\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 获取预测结果\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100  # 计算准确率\n",
    "\n",
    "    # 每个epoch结束后输出\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "print(f'训练时长： {time.time() - train_start}s')"
   ],
   "id": "e94d9a0871b9970b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 假设 xTe 和 yTe 是 pandas DataFrame 或 Series\n",
    "# 数据预处理\n",
    "xTe_scaled = scaler.fit_transform(xTe)  # 使用与训练数据相同的标准化参数\n",
    "xTe_tensor = torch.tensor(xTe_scaled, dtype=torch.float32).to(device)\n",
    "yTe_tensor = torch.tensor(yTe.values.ravel(), dtype=torch.long).to(device)\n",
    "\n",
    "# 创建数据加载器\n",
    "test_dataset = TensorDataset(xTe_tensor, yTe_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于计算准确率的变量\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 不计算梯度，因为在评估模式下不需要进行反向传播\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on test set: {accuracy * 100:.2f}%')"
   ],
   "id": "e1ecc2eefa1d90f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Pytorch Transformer ##",
   "id": "cf72af33f38ca812"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, num_layers, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.model_dim = input_dim  # 通常情况下，模型维度与输入维度相同\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.model_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=512,  # 前馈网络的维度\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Transformer Encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(self.model_dim, self.num_classes)\n",
    "\n",
    "        # Batch Normalization\n",
    "        self.bn = nn.BatchNorm1d(self.model_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 增加一个假的序列维度\n",
    "        x = x.unsqueeze(1)\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Batch Normalization\n",
    "        x = self.bn(x[:, 0, :])  # 取序列的第一个元素进行批量归一化\n",
    "\n",
    "        # 输出层\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# 补充维度\n",
    "n_samples_xTr = xTr.shape[0]\n",
    "n_samples_xTe = xTe.shape[0]\n",
    "for i in range(1, 4):  # 从 1 到 3，因为需要添加三列\n",
    "    xTr[f'pad{i}'] = 0  # 添加填充列，初始化为 0\n",
    "    xTe[f'pad{i}'] = 0  # 添加填充列，初始化为 0\n",
    "\n",
    "# 参数设置\n",
    "input_dim = xTr.shape[1]  # 输入特征的维度\n",
    "num_classes = 3  # 类别数\n",
    "num_heads = 10  # 注意力头的数量\n",
    "num_layers = 3  # Transformer层的数量\n",
    "dropout = 0.8  # Dropout比率\n",
    "\n",
    "# 创建模型\n",
    "model = TransformerModel(input_dim, num_classes, num_heads, num_layers, dropout).to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 数据加载\n",
    "# 假设 xTr 和 xTe 已经是适当的 torch.Tensor 对象\n",
    "xTr_values = xTr.values.astype(float)\n",
    "xTe_values = xTe.values.astype(float)\n",
    "\n",
    "xTr_tensor = torch.tensor(xTr_values, dtype=torch.float32).to(device)\n",
    "xTe_tensor = torch.tensor(xTe_values, dtype=torch.float32).to(device)\n",
    "yTr_tensor = torch.tensor(yTr.values, dtype=torch.long).to(device).squeeze(1)\n",
    "yTe_tensor = torch.tensor(yTe.values, dtype=torch.long).to(device).squeeze(1)\n",
    "# 转换为 one-hot 编码\n",
    "yTr_tensor = F.one_hot(yTr_tensor, num_classes=num_classes).float()\n",
    "yTe_tensor = F.one_hot(yTe_tensor, num_classes=num_classes).float()\n",
    "\n",
    "# 数据加载器\n",
    "train_dataset = TensorDataset(xTr_tensor, yTr_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(xTe_tensor, yTe_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "train_start = time.time()\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(500):  # 运行更多的 epoch 以获得更好的结果\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)  # 累计损失\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 获取预测结果\n",
    "        _, truth = torch.max(labels.data, 1)\n",
    "        total += truth.size(0)\n",
    "        correct += (predicted == truth).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100  # 计算准确率\n",
    "\n",
    "    # 每个epoch结束后输出\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "print(f'训练时长： {time.time() - train_start}s')\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用于计算准确率的变量\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 不计算梯度，因为在评估模式下不需要进行反向传播\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, truth = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == truth).sum().item()\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on test set: {accuracy * 100:.2f}%')"
   ],
   "id": "f301286ecdd3d9d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
